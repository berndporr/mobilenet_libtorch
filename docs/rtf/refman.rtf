{\rtf1\ansi\ansicpg1252\uc1 \deff0\deflang1033\deflangfe1033
{\fonttbl {\f0\froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}
{\f1\fswiss\fcharset0\fprq2{\*\panose 020b0604020202020204}Arial;}
{\f2\fmodern\fcharset0\fprq1{\*\panose 02070309020205020404}Courier New;}
{\f3\froman\fcharset2\fprq2{\*\panose 05050102010706020507}Symbol;}
}
{\colortbl;\red0\green0\blue0;\red0\green0\blue255;\red0\green255\blue255;\red0\green255\blue0;\red255\green0\blue255;\red255\green0\blue0;\red255\green255\blue0;\red255\green255\blue255;\red0\green0\blue128;\red0\green128\blue128;\red0\green128\blue0;\red128\green0\blue128;\red128\green0\blue0;\red128\green128\blue0;\red128\green128\blue128;\red192\green192\blue192;\red0\green128\blue0;\red96\green64\blue32;\rede0\green128\blue0;\red128\green0\blue0;\red128\green96\blue32;\red0\green32\blue128;\red0\green128\blue128;\red255\green0\blue255;\red0\green0\blue0;\red112\green0\blue112;\red255\green0\blue0;}
{\stylesheet
{\widctlpar\adjustright \fs20\cgrid \snext0 Normal;}
{\paperw11900\paperh16840\margl1800\margr1800\margt1440\margb1440\gutter0\ltrsect}
{\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid \sbasedon0 \snext0 heading 1;}
{\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid \sbasedon0 \snext0 heading 2;}
{\s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid \sbasedon0 \snext0 heading 3;}
{\s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext0 heading 4;}{\*\cs10 \additive Default Paragraph Font;}
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext0 heading 5;}{\*\cs10 \additive Default Paragraph Font;}
{\s15\qc\sb240\sa60\widctlpar\outlinelevel0\adjustright \b\f1\fs32\kerning28\cgrid \sbasedon0 \snext15 Title;}
{\s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid \sbasedon0 \snext16 Subtitle;}
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid \sbasedon0 \snext17 BodyText;}
{\s18\widctlpar\fs22\cgrid \sbasedon0 \snext18 DenseText;}
{\s28\widctlpar\tqc\tx4320\tqr\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext28 header;}
{\s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid \sbasedon0 \snext29 footer;}
{\s30\li360\sa60\sb120\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext30 GroupHeader;}
{\s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext41 Code Example 0;}
{\s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext42 Code Example 1;}
{\s42\li720\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext43 Code Example 2;}
{\s43\li1080\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext44 Code Example 3;}
{\s44\li1440\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext45 Code Example 4;}
{\s45\li1800\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext46 Code Example 5;}
{\s46\li2160\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext47 Code Example 6;}
{\s47\li2520\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext48 Code Example 7;}
{\s48\li2880\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext49 Code Example 8;}
{\s49\li3240\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext50 Code Example 9;}
{\s50\li3600\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext51 Code Example 10;}
{\s51\li3960\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext52 Code Example 11;}
{\s52\li4320\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext53 Code Example 12;}
{\s53\li4680\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext53 Code Example 13;}
{\s60\li0\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext61 List Continue 0;}
{\s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext62 List Continue 1;}
{\s62\li720\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext63 List Continue 2;}
{\s63\li1080\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext64 List Continue 3;}
{\s64\li1440\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext65 List Continue 4;}
{\s65\li1800\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext66 List Continue 5;}
{\s66\li2160\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext67 List Continue 6;}
{\s67\li2520\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext68 List Continue 7;}
{\s68\li2880\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext69 List Continue 8;}
{\s69\li3240\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext70 List Continue 9;}
{\s70\li3600\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext71 List Continue 10;}
{\s71\li3960\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext72 List Continue 11;}
{\s72\li4320\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext73 List Continue 12;}
{\s73\li4680\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext73 List Continue 13;}
{\s80\li0\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext81 DescContinue 0;}
{\s81\li360\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext82 DescContinue 1;}
{\s82\li720\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext83 DescContinue 2;}
{\s83\li1080\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext84 DescContinue 3;}
{\s84\li1440\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext85 DescContinue 4;}
{\s85\li1800\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext86 DescContinue 5;}
{\s86\li2160\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext87 DescContinue 6;}
{\s87\li2520\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext88 DescContinue 7;}
{\s88\li2880\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext89 DescContinue 8;}
{\s89\li3240\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext90 DescContinue 9;}
{\s90\li3600\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext91 DescContinue 10;}
{\s91\li3960\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext92 DescContinue 11;}
{\s92\li4320\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext93 DescContinue 12;}
{\s93\li4680\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext93 DescContinue 13;}
{\s100\li0\sa30\sb30\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext101 LatexTOC 0;}
{\s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext102 LatexTOC 1;}
{\s102\li720\sa24\sb24\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext103 LatexTOC 2;}
{\s103\li1080\sa21\sb21\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext104 LatexTOC 3;}
{\s104\li1440\sa18\sb18\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext105 LatexTOC 4;}
{\s105\li1800\sa15\sb15\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext106 LatexTOC 5;}
{\s106\li2160\sa12\sb12\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext107 LatexTOC 6;}
{\s107\li2520\sa9\sb9\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext108 LatexTOC 7;}
{\s108\li2880\sa6\sb6\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext109 LatexTOC 8;}
{\s109\li3240\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext110 LatexTOC 9;}
{\s110\li3600\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext111 LatexTOC 10;}
{\s111\li3960\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext112 LatexTOC 11;}
{\s112\li4320\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext113 LatexTOC 12;}
{\s113\li4680\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext113 LatexTOC 13;}
{\s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext121 \sautoupd List Bullet 0;}
{\s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext122 \sautoupd List Bullet 1;}
{\s122\fi-360\li1080\widctlpar\jclisttab\tx1080{\*\pn \pnlvlbody\ilvl0\ls3\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext123 \sautoupd List Bullet 2;}
{\s123\fi-360\li1440\widctlpar\jclisttab\tx1440{\*\pn \pnlvlbody\ilvl0\ls4\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext124 \sautoupd List Bullet 3;}
{\s124\fi-360\li1800\widctlpar\jclisttab\tx1800{\*\pn \pnlvlbody\ilvl0\ls5\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext125 \sautoupd List Bullet 4;}
{\s125\fi-360\li2160\widctlpar\jclisttab\tx2160{\*\pn \pnlvlbody\ilvl0\ls6\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext126 \sautoupd List Bullet 5;}
{\s126\fi-360\li2520\widctlpar\jclisttab\tx2520{\*\pn \pnlvlbody\ilvl0\ls7\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext127 \sautoupd List Bullet 6;}
{\s127\fi-360\li2880\widctlpar\jclisttab\tx2880{\*\pn \pnlvlbody\ilvl0\ls8\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext128 \sautoupd List Bullet 7;}
{\s128\fi-360\li3240\widctlpar\jclisttab\tx3240{\*\pn \pnlvlbody\ilvl0\ls9\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext129 \sautoupd List Bullet 8;}
{\s129\fi-360\li3600\widctlpar\jclisttab\tx3600{\*\pn \pnlvlbody\ilvl0\ls10\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext130 \sautoupd List Bullet 9;}
{\s130\fi-360\li3960\widctlpar\jclisttab\tx3960{\*\pn \pnlvlbody\ilvl0\ls11\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext131 \sautoupd List Bullet 10;}
{\s131\fi-360\li4320\widctlpar\jclisttab\tx4320{\*\pn \pnlvlbody\ilvl0\ls12\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext132 \sautoupd List Bullet 11;}
{\s132\fi-360\li4680\widctlpar\jclisttab\tx4680{\*\pn \pnlvlbody\ilvl0\ls13\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext133 \sautoupd List Bullet 12;}
{\s133\fi-360\li5040\widctlpar\jclisttab\tx5040{\*\pn \pnlvlbody\ilvl0\ls14\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext133 \sautoupd List Bullet 13;}
{\s140\fi-360\li360\widctlpar\fs20\cgrid \sbasedon0 \snext141 \sautoupd List Enum 0;}
{\s141\fi-360\li720\widctlpar\fs20\cgrid \sbasedon0 \snext142 \sautoupd List Enum 1;}
{\s142\fi-360\li1080\widctlpar\fs20\cgrid \sbasedon0 \snext143 \sautoupd List Enum 2;}
{\s143\fi-360\li1440\widctlpar\fs20\cgrid \sbasedon0 \snext144 \sautoupd List Enum 3;}
{\s144\fi-360\li1800\widctlpar\fs20\cgrid \sbasedon0 \snext145 \sautoupd List Enum 4;}
{\s145\fi-360\li2160\widctlpar\fs20\cgrid \sbasedon0 \snext146 \sautoupd List Enum 5;}
{\s146\fi-360\li2520\widctlpar\fs20\cgrid \sbasedon0 \snext147 \sautoupd List Enum 6;}
{\s147\fi-360\li2880\widctlpar\fs20\cgrid \sbasedon0 \snext148 \sautoupd List Enum 7;}
{\s148\fi-360\li3240\widctlpar\fs20\cgrid \sbasedon0 \snext149 \sautoupd List Enum 8;}
{\s149\fi-360\li3600\widctlpar\fs20\cgrid \sbasedon0 \snext150 \sautoupd List Enum 9;}
{\s150\fi-360\li3960\widctlpar\fs20\cgrid \sbasedon0 \snext151 \sautoupd List Enum 10;}
{\s151\fi-360\li4320\widctlpar\fs20\cgrid \sbasedon0 \snext152 \sautoupd List Enum 11;}
{\s152\fi-360\li4680\widctlpar\fs20\cgrid \sbasedon0 \snext153 \sautoupd List Enum 12;}
{\s153\fi-360\li5040\widctlpar\fs20\cgrid \sbasedon0 \snext153 \sautoupd List Enum 13;}
}
{\info 
{\title {\comment Mobilenet with Libtorch }Mobilenet with Libtorch}
{\comment Generated by doxygen 1.9.8.}
}\pard\plain 
\sectd\pgnlcrm
{\footer \s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid {\chpgn}}
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
\vertalc\qc\par\par\par\par\par\par\par
\pard\plain \s15\qc\sb240\sa60\widctlpar\outlinelevel0\adjustright \b\f1\fs32\kerning28\cgrid 
{\field\fldedit {\*\fldinst TITLE \\*MERGEFORMAT}{\fldrslt Mobilenet with Libtorch}}\par
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
\par
\par\par\par\par\par\par\par\par\par\par\par\par
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
{\field\fldedit {\*\fldinst AUTHOR \\*MERGEFORMAT}{\fldrslt AUTHOR}}\par
Version \par\page\page\vertalt
\pard\plain 
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid Table of Contents\par
\pard\plain \par
{\field\fldedit {\*\fldinst TOC \\f \\*MERGEFORMAT}{\fldrslt Table of contents}}\par
\pard\plain 
\sect \sbkpage \pgndec \pgnrestart
\sect \sectd \sbknone
{\footer \s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid {\chpgn}}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
\par \pard\plain 
\pard\plain \s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
MobileNetV2 libtorch\par \pard\plain 
{\tc\tcl1 \v MobileNetV2 libtorch}
{\xe \v MobileNetV2 libtorch}
{\bkmkstart AAAAAAAAAN}
{\bkmkend AAAAAAAAAN}
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\bkmkstart AAAAAAAAAO}
{\bkmkend AAAAAAAAAO}
C++ version of {\b MobileNetV2} using libtorch which can import the pre-trained weights from torchvision.\par
Importing the weights instead of using the JIT has the advantage that one can do transfer learning also on an edge device, for example, to adapt to different situations locally.\par
This implementation follows very closely the {\f2 torchvision implementation of mobilenet v2}.\par
Mobilenet is described {\f2 here}.\par
Then simply include {\f2 {\b mobilenet_v2.h}}  into your own project.\par
{\pard\plain \s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid {\tc\tcl1 Credit} \par}
(C) 2025 {\f2 Bernd Porr}, GPLv3 \par
}}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Hierarchical Index\par \pard\plain 
{\tc \v Hierarchical Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
Class Hierarchy\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid This inheritance list is sorted roughly, but not completely, alphabetically:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
torch::nn::Module
{
\par
\pard\plain \s102\li720\sa24\sb24\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
MobileNetV2\tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAB \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
}\par
}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Class Index\par \pard\plain 
{\tc \v Class Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
Class List\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid Here are the classes, structs, unions and interfaces with brief descriptions:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
{\b {\b MobileNetV2} ({\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Implementation of {\b MobileNetV2} as done in py-torchvision See: // {\f2 https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py#L66} })} \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAB \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
\par}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
File Index\par \pard\plain 
{\tc \v File Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
File List\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid Here is a list of all documented files with brief descriptions:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
{\b {\b mobilenet_v2.h} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAA \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
\par}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Class Documentation{\tc \v Class Documentation}
\par \pard\plain 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
MobileNetV2 Class Reference\par \pard\plain 
{\tc\tcl2 \v MobileNetV2}
{\xe \v MobileNetV2}
{\bkmkstart AAAAAAAAAB}
{\bkmkend AAAAAAAAAB}
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Implementation of {\b MobileNetV2} as done in py-torchvision See: // {\f2 https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py#L66}. }}\par
{
{\f2 #include <mobilenet_v2.h>}}\par
Inheritance diagram for MobileNetV2:{
\pard\plain 
\par\pard \qc {\field\flddirty {\*\fldinst INCLUDEPICTURE "classMobileNetV2__inherit__graph.png" \\d \\*MERGEFORMAT}{\fldrslt IMAGE}}\par
}
\par
Collaboration diagram for MobileNetV2:{
\pard\plain 
\par\pard \qc {\field\flddirty {\*\fldinst INCLUDEPICTURE "classMobileNetV2__coll__graph.png" \\d \\*MERGEFORMAT}{\fldrslt IMAGE}}\par
}
\par
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Public Member Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b MobileNetV2} (int num_classes=1000, float width_mult=1.0f, int round_nearest=8, float dropout=0.2)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Construct a new {\b MobileNetV2} object. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b getNinputChannels4Classifier} () const\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Gets the number of input channels for the classfier. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
torch::Tensor {\b forward} (torch::Tensor x)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Performs the forward pass. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

void {\b initialize_weights} (){\bkmkstart AAAAAAAAAC}
{\bkmkend AAAAAAAAAC}
\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Initialize conv/bn/linear similar to torchvision defaults. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
void {\b load_weights} (std::string pt)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Loads a .pt weight file containing a dict with key/parameter pairs. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
void {\b replaceClassifier} (torch::nn::Sequential &newClassifier)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Replaces classifer with a new one. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
void {\b setFeatureLearning} (bool doLearn)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Enables/disables learning in the feature layers. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
torch::nn::Sequential {\b getClassifier} () const\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Gets the Classifier object. }{
}\par
}\par}
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Static Public Member Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
static torch::Tensor {\b preprocess} (cv::Mat img, bool resizeOnly=false)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Preprocessing of an openCV image for inference or learning. }{
}\par
}\par}
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Static Public Attributes\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
static constexpr char {\b featuresModuleName} [] = "features"\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Name of the features submodule. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
static constexpr char {\b classifierModuleName} [] = "classifier"\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Name of the classifier submodule. }{
}\par
}\par}
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Implementation of {\b MobileNetV2} as done in py-torchvision See: // {\f2 https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py#L66}. \par
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Constructor & Destructor Documentation\par
\pard\plain 
{\xe \v MobileNetV2\:MobileNetV2}
{\xe \v MobileNetV2\:MobileNetV2}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
MobileNetV2::MobileNetV2 (int  {\i num_classes} = {\f2 1000}, float  {\i width_mult} = {\f2 1.0f}, int  {\i round_nearest} = {\f2 8}, float  {\i dropout} = {\f2 0.2}){\f2 [inline]}}}
\par
{\bkmkstart AAAAAAAAAD}
{\bkmkend AAAAAAAAAD}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Construct a new {\b MobileNetV2} object. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
If you want to load the weights from torchvision into the classifier use the default values for the parameters.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i num_classes} \cell }{Number of classes. \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i width_mult} \cell }{Width multiplier - adjusts number of channels in each layer by this amount. \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i round_nearest} \cell }{Round the number of channels in each layer to be a multiple of this number. \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i dropout} \cell }{Dropout probability for the dropout layer in the classifier. \cell }
{\row }
}
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Member Function Documentation\par
\pard\plain 
{\xe \v forward\:MobileNetV2}
{\xe \v MobileNetV2\:forward}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
torch::Tensor MobileNetV2::forward (torch::Tensor  {\i x}){\f2 [inline]}}}
\par
{\bkmkstart AAAAAAAAAE}
{\bkmkend AAAAAAAAAE}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Performs the forward pass. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\par
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i x} \cell }{The batch of input images. \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
torch::Tensor The category scores for the different labels. \par
}}}}
{\xe \v getClassifier\:MobileNetV2}
{\xe \v MobileNetV2\:getClassifier}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
torch::nn::Sequential MobileNetV2::getClassifier () const{\f2 [inline]}}}
\par
{\bkmkstart AAAAAAAAAF}
{\bkmkend AAAAAAAAAF}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Gets the Classifier object. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Gets a pointer to the classifier, for example to attach an optimiser with it for transfer learning.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
torch::nn::Sequential \par
}}}}
{\xe \v getNinputChannels4Classifier\:MobileNetV2}
{\xe \v MobileNetV2\:getNinputChannels4Classifier}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
int MobileNetV2::getNinputChannels4Classifier () const{\f2 [inline]}}}
\par
{\bkmkstart AAAAAAAAAG}
{\bkmkend AAAAAAAAAG}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Gets the number of input channels for the classfier. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
This will make it easy to replace the classifier with anything the user wants by creating their own torch::nn::Sequential() for the classifier.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
int The number of intput channels to the classifer class "classfier". \par
}}}}
{\xe \v load_weights\:MobileNetV2}
{\xe \v MobileNetV2\:load_weights}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
void MobileNetV2::load_weights (std::string  {\i pt}){\f2 [inline]}}}
\par
{\bkmkstart AAAAAAAAAH}
{\bkmkend AAAAAAAAAH}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Loads a .pt weight file containing a dict with key/parameter pairs. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
See {\f2 https://github.com/pytorch/pytorch/issues/36577}\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i pt} \cell }{filename of the .pt weight file. \cell }
{\row }
}
}}
{\xe \v preprocess\:MobileNetV2}
{\xe \v MobileNetV2\:preprocess}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
static torch::Tensor MobileNetV2::preprocess (cv::Mat  {\i img}, bool  {\i resizeOnly} = {\f2 false}){\f2 [inline]}, {\f2 [static]}}}
\par
{\bkmkstart AAAAAAAAAI}
{\bkmkend AAAAAAAAAI}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Preprocessing of an openCV image for inference or learning. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
The images are resized to 256x256, followed by a central crop of 224x224. Finally the values are first rescaled to [0.0, 1.0] and then normalized using mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225].\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i img} \cell }{8bit BGR openCV image with an aspect ratio of 1:1. \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i resizeOnly} \cell }{If true the image is only resized to 224x224 but not cropped. Default: false. \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
torch::Tensor The image as a tensor ready to be used for inference and learning. \par
}}}}
{\xe \v replaceClassifier\:MobileNetV2}
{\xe \v MobileNetV2\:replaceClassifier}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
void MobileNetV2::replaceClassifier (torch::nn::Sequential &  {\i newClassifier}){\f2 [inline]}}}
\par
{\bkmkstart AAAAAAAAAJ}
{\bkmkend AAAAAAAAAJ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Replaces classifer with a new one. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
This is done for transfer learning where the classifier is replaced with a new one. {\par
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i newClassifier} \cell }{The new classifier. \cell }
{\row }
}
}}
{\xe \v setFeatureLearning\:MobileNetV2}
{\xe \v MobileNetV2\:setFeatureLearning}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
void MobileNetV2::setFeatureLearning (bool  {\i doLearn}){\f2 [inline]}}}
\par
{\bkmkstart AAAAAAAAAK}
{\bkmkend AAAAAAAAAK}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Enables/disables learning in the feature layers. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
For transfer learning one needs to disable learning in the feature layers. \par
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Member Data Documentation\par
\pard\plain 
{\xe \v classifierModuleName\:MobileNetV2}
{\xe \v MobileNetV2\:classifierModuleName}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
constexpr char MobileNetV2::classifierModuleName[] = "classifier"{\f2 [static]}, {\f2 [constexpr]}}}
\par
{\bkmkstart AAAAAAAAAL}
{\bkmkend AAAAAAAAAL}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Name of the classifier submodule. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
This is used for module registration and appears as part of the key in named_parametes. The name of the classifier module is needed when replacing the default classifier. \par
}}
{\xe \v featuresModuleName\:MobileNetV2}
{\xe \v MobileNetV2\:featuresModuleName}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
constexpr char MobileNetV2::featuresModuleName[] = "features"{\f2 [static]}, {\f2 [constexpr]}}}
\par
{\bkmkstart AAAAAAAAAM}
{\bkmkend AAAAAAAAAM}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Name of the features submodule. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
This is used for module registration and appears as part of the key in named_parametes. \par
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
The documentation for this class was generated from the following file:{\par
\pard\plain \s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
mobilenet_v2.h\par
}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
File Documentation{\tc \v File Documentation}
\par \pard\plain 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
mobilenet_v2.h\par \pard\plain 
{\bkmkstart AAAAAAAAAA}
{\bkmkend AAAAAAAAAA}
{
\pard\plain \s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 1 {\cf21 #pragma once}\par
2 \par
3 {\cf21 #include <torch/torch.h>}\par
4 {\cf21 #include <vector>}\par
5 {\cf21 #include <algorithm>}\par
6 {\cf21 #include <fstream>}\par
7 {\cf21 #include <string>}\par
8 {\cf21 #include <regex>}\par
9 {\cf21 #include <filesystem>}\par
10 {\cf21 #include <iostream>}\par
11 {\cf21 #include <system_error>}\par
12 {\cf21 #include <opencv2/opencv.hpp>}\par
13 \par
14 {\cf20 /***}\par
15 {\cf20  * MobileNetV2 C++ Implementation (LibTorch).}\par
16 {\cf20  * It's able to load pre-trained weights from torchvision}\par
17 {\cf20  * and has the neccessary methods to enable transfer learning.}\par
18 {\cf20  * (c) 2025 Bernd Porr, GPLv3.}\par
19 {\cf20  ***/}\par
20 \par
21 {\cf21 #ifdef NDEBUG}\par
22 {\cf17 constexpr} {\cf18 bool} debugOutput = {\cf17 false};\par
23 {\cf21 #else}\par
24 {\cf17 constexpr} {\cf18 bool} debugOutput = {\cf17 true};\par
25 {\cf21 #endif}\par
26 \par
31 {\cf17 class }MobileNetV2 : {\cf17 public} torch::nn::Module\par
32 \{\par
33 {\cf17 public}:\par
44     MobileNetV2({\cf18 int} num_classes = 1000, {\cf18 float} width_mult = 1.0f, {\cf18 int} round_nearest = 8, {\cf18 float} dropout = 0.2)\par
45     \{\par
46         {\cf18 int} input_channels = 32;\par
47         input_channels = make_divisible(input_channels * width_mult, round_nearest);\par
48         features_output_channels = make_divisible(features_output_channels * std::max(1.0f, width_mult), round_nearest);\par
49 \par
50         features = torch::nn::Sequential();\par
51 \par
52         features->push_back(\par
53             Conv2dNormActivation(3,\par
54                                  input_channels,\par
55                                  {\cf20 /*kernel_size=*/}3,\par
56                                  {\cf20 /*stride =*/}2));\par
57 \par
58         {\cf20 // inverted residual blocks}\par
59         {\cf19 for} ({\cf17 const} {\cf17 auto} &cfg : inverted_residual_setting)\par
60         \{\par
61             {\cf17 const} {\cf18 int} t = cfg[0];\par
62             {\cf17 const} {\cf18 int} c = cfg[1];\par
63             {\cf17 const} {\cf18 int} n = cfg[2];\par
64             {\cf17 const} {\cf18 int} s = cfg[3];\par
65 \par
66             {\cf18 int} output_channel = make_divisible(c * width_mult, round_nearest);\par
67             {\cf19 for} ({\cf18 int} i = 0; i < n; ++i)\par
68             \{\par
69                 {\cf17 const} {\cf18 int} stride = (i == 0) ? s : 1;\par
70                 features->push_back(\par
71                     InvertedResidual(input_channels, output_channel, stride, t));\par
72                 input_channels = output_channel;\par
73             \}\par
74         \}\par
75 \par
76         features->push_back(\par
77             Conv2dNormActivation(input_channels,\par
78                                  features_output_channels,\par
79                                  {\cf20 /*kernel_size=*/}1));\par
80 \par
81         register_module(featuresModuleName, features);\par
82 \par
83         {\cf20 // classifier: Dropout + Linear}\par
84         classifier = torch::nn::Sequential();\par
85         classifier->push_back(torch::nn::Dropout(torch::nn::DropoutOptions(dropout)));\par
86         classifier->push_back(torch::nn::Linear(torch::nn::LinearOptions(features_output_channels, num_classes)));\par
87         register_module(classifierModuleName, classifier);\par
88     \}\par
89 \par
94     {\cf17 static} {\cf17 constexpr} {\cf18 char} featuresModuleName[] = {\cf22 "features"};\par
95 \par
102     {\cf17 static} {\cf17 constexpr} {\cf18 char} classifierModuleName[] = {\cf22 "classifier"};\par
103 \par
111     {\cf18 int} getNinputChannels4Classifier(){\cf17  const}\par
112 {\cf17     }\{\par
113         {\cf19 return} features_output_channels;\par
114     \}\par
115 \par
122     torch::Tensor forward(torch::Tensor x)\par
123     \{\par
124         x = features->forward(x);\par
125         {\cf17 const} torch::nn::functional::AdaptiveAvgPool2dFuncOptions &ar = torch::nn::functional::AdaptiveAvgPool2dFuncOptions(\{1, 1\});\par
126         x = torch::nn::functional::adaptive_avg_pool2d(x, ar);\par
127         x = torch::flatten(x, 1);\par
128         x = classifier->forward(x);\par
129         {\cf19 return} x;\par
130     \}\par
131 \par
135     {\cf18 void} initialize_weights()\par
136     \{\par
137         {\cf19 for} ({\cf17 auto} &module : modules({\cf20 /*include_self=*/}{\cf17 false}))\par
138         \{\par
139             {\cf19 if} ({\cf17 auto} M = {\cf17 dynamic_cast<}torch::nn::Conv2dImpl *{\cf17 >}(module.get()))\par
140             \{\par
141                 torch::nn::init::kaiming_normal_(M->weight, {\cf20 /*a=*/}0, torch::kFanOut, torch::kReLU);\par
142                 {\cf19 if} (M->options.bias())\par
143                     torch::nn::init::zeros_(M->bias);\par
144             \}\par
145             {\cf19 else} {\cf19 if} ({\cf17 auto} M = {\cf17 dynamic_cast<}torch::nn::BatchNorm2dImpl *{\cf17 >}(module.get()))\par
146             \{\par
147                 torch::nn::init::ones_(M->weight);\par
148                 torch::nn::init::zeros_(M->bias);\par
149             \}\par
150             {\cf19 else} {\cf19 if} ({\cf17 auto} M = {\cf17 dynamic_cast<}torch::nn::LinearImpl *{\cf17 >}(module.get()))\par
151             \{\par
152                 torch::nn::init::normal_(M->weight, 0.0, 0.01);\par
153                 torch::nn::init::zeros_(M->bias);\par
154             \}\par
155         \}\par
156     \}\par
157 \par
164     {\cf18 void} load_weights(std::string pt)\par
165     \{\par
166         std::ifstream input(pt, std::ios::binary);\par
167         input.exceptions(input.failbit);\par
168         std::vector<char> bytes(\par
169             (std::istreambuf_iterator<char>(input)),\par
170             (std::istreambuf_iterator<char>()));\par
171         input.close();\par
172         {\cf17 const} c10::Dict<c10::IValue, c10::IValue> weights = torch::pickle_load(bytes).toGenericDict();\par
173         {\cf19 if} (debugOutput)\par
174         \{\par
175             std::cerr << {\cf22 "Parameters we have in this model here: "} << std::endl;\par
176             {\cf19 for} ({\cf17 auto} {\cf17 const} &m : named_parameters())\par
177             \{\par
178                 {\cf17 auto} k = ourkey2torchvision(m.key());\par
179                 std::cerr << m.key() << {\cf22 "->"} << k << {\cf22 ": "} << m.value().sizes() << std::endl;\par
180             \}\par
181             std::cerr << {\cf22 "Named buffers we have in this model here: "} << std::endl;\par
182             {\cf19 for} ({\cf17 const} {\cf17 auto} &b : named_buffers())\par
183             \{\par
184                 {\cf17 auto} k = ourkey2torchvision(b.key());\par
185                 std::cout << b.key() << {\cf22 "->"} << k << {\cf22 ": "} << b.value().sizes() << std::endl;\par
186             \}\par
187             std::cerr << {\cf22 "Parameters we have in the weight file "} << pt << {\cf22 ":"} << std::endl;\par
188             {\cf19 for} ({\cf17 auto} {\cf17 const} &w : weights)\par
189             \{\par
190                 std::cerr << w.key() << {\cf22 ": "} << w.value().toTensor().sizes() << std::endl;\par
191             \}\par
192         \}\par
193         torch::NoGradGuard no_grad;\par
194         {\cf19 if} (debugOutput)\par
195             std::cerr << {\cf22 "Loading weights"} << std::endl;\par
196         {\cf19 for} ({\cf17 auto} &m : named_parameters())\par
197         \{\par
198             {\cf17 const} std::string model_key = m.key();\par
199             {\cf17 const} std::string model_key4torchvision = ourkey2torchvision(model_key);\par
200             {\cf19 if} (debugOutput)\par
201                 std::cerr << {\cf22 "Searching for: "} << model_key4torchvision << {\cf22 ": "} << m.value().sizes() << std::endl;\par
202             {\cf18 bool} foundit = {\cf17 false};\par
203             {\cf19 for} ({\cf17 auto} {\cf17 const} &w : weights)\par
204             \{\par
205                 {\cf19 if} (model_key4torchvision == w.key())\par
206                 \{\par
207                     {\cf19 if} (debugOutput)\par
208                         std::cerr << {\cf22 "Found it: "} << w.key() << std::endl;\par
209                     m.value().copy_(w.value().toTensor());\par
210                     foundit = {\cf17 true};\par
211                     {\cf19 break};\par
212                 \}\par
213             \}\par
214             {\cf19 if} (!foundit)\par
215                 std::cerr << {\cf22 "Key: "} << model_key4torchvision << {\cf22 " could not be found!"} << std::endl;\par
216         \}\par
217         {\cf19 if} (debugOutput)\par
218             std::cerr << {\cf22 "Loading named buffers"} << std::endl;\par
219         {\cf19 for} ({\cf17 auto} &b : named_buffers())\par
220         \{\par
221             std::string model_key = b.key();\par
222             std::string model_key4torchvision = ourkey2torchvision(model_key);\par
223             {\cf19 if} (debugOutput)\par
224                 std::cerr << {\cf22 "Searching for: "} << model_key4torchvision << {\cf22 ": "} << b.value().sizes() << std::endl;\par
225             {\cf18 bool} foundit = {\cf17 false};\par
226             {\cf19 for} ({\cf17 auto} {\cf17 const} &w : weights)\par
227             \{\par
228                 {\cf19 if} (model_key4torchvision == w.key())\par
229                 \{\par
230                     {\cf19 if} (debugOutput)\par
231                         std::cerr << {\cf22 "Found it: "} << w.key() << std::endl;\par
232                     b.value().copy_(w.value().toTensor());\par
233                     foundit = {\cf17 true};\par
234                     {\cf19 break};\par
235                 \}\par
236             \}\par
237             {\cf19 if} (!foundit)\par
238                 std::cerr << {\cf22 "Key: "} << model_key4torchvision << {\cf22 " could not be found!"} << std::endl;\par
239         \}\par
240     \}\par
241 \par
252     {\cf17 static} torch::Tensor preprocess(cv::Mat img, {\cf18 bool} resizeOnly = {\cf17 false})\par
253     \{\par
254         {\cf17 constexpr} {\cf18 int} imageSizeBeforeCrop = 256;\par
255         {\cf17 constexpr} {\cf18 int} finalImageSize = 224;\par
256         {\cf17 constexpr} {\cf18 int} numChannels = 3; {\cf20 // colour}\par
257 \par
258         {\cf19 if} (img.depth() != CV_8U)\par
259             {\cf19 throw} std::invalid_argument({\cf22 "Image is not 8bit."});\par
260         {\cf19 if} (img.channels() != numChannels)\par
261             {\cf19 throw} std::invalid_argument({\cf22 "Image is not BGR / colour."});\par
262 \par
263         {\cf19 if} (resizeOnly)\par
264         \{\par
265             cv::resize(img, img, cv::Size(finalImageSize, finalImageSize));\par
266         \}\par
267         {\cf19 else}\par
268         \{\par
269             cv::resize(img, img, cv::Size(imageSizeBeforeCrop, imageSizeBeforeCrop));\par
270             {\cf17 constexpr} {\cf18 int} start = (imageSizeBeforeCrop - finalImageSize) / 2;\par
271             {\cf17 const} cv::Rect roi(start, start, finalImageSize, finalImageSize);\par
272             img = img(roi).clone();\par
273         \}\par
274         cv::cvtColor(img, img, cv::COLOR_BGR2RGB);\par
275 \par
276         torch::Tensor tensor = torch::from_blob(img.data, \{img.rows, img.cols, 3\}, torch::kByte);\par
277         tensor = tensor.permute(\{2, 0, 1\}).to(torch::kFloat).div_(255.0);\par
278         tensor = torch::data::transforms::Normalize(\{0.485, 0.456, 0.406\}, \{0.229, 0.224, 0.225\})(tensor);\par
279         {\cf19 return} tensor;\par
280     \}\par
281 \par
288     {\cf18 void} replaceClassifier(torch::nn::Sequential &newClassifier)\par
289     \{\par
290         classifier = newClassifier;\par
291         replace_module(MobileNetV2::classifierModuleName, newClassifier);\par
292     \}\par
293 \par
300     {\cf18 void} setFeatureLearning({\cf18 bool} doLearn) \{\par
301         {\cf19 for} ({\cf17 auto} &p : features->parameters())\par
302         p.requires_grad_(doLearn);\par
303     \}\par
304 \par
312     torch::nn::Sequential getClassifier(){\cf17  const }\{\par
313         {\cf19 return} classifier;\par
314     \}\par
315 \par
316 {\cf17 private}:\par
320     torch::nn::Sequential classifier\{{\cf17 nullptr}\};\par
321 \par
325     torch::nn::Sequential features\{{\cf17 nullptr}\};\par
326 \par
327     {\cf20 // Helper which maps the libtorch keys to pytorch keys.}\par
328     std::string ourkey2torchvision(std::string k){\cf17  const}\par
329 {\cf17     }\{\par
330         {\cf20 // called simply "conv" in the weights file}\par
331         k = std::regex_replace(k, std::regex(InvertedResidual::className), {\cf22 "conv"});\par
332         {\cf20 // not used at all in the weights file}\par
333         {\cf17 const} std::string r = std::string(Conv2dNormActivation::className) + {\cf22 "\\\\."};\par
334         k = std::regex_replace(k, std::regex(r), {\cf22 ""});\par
335         {\cf19 return} k;\par
336     \}\par
337 \par
338     {\cf20 // Makes a value divisible.}\par
339     {\cf17 inline} {\cf18 int} make_divisible({\cf18 int} v, {\cf18 int} divisor = 8, {\cf18 int} min_value = -1){\cf17  const}\par
340 {\cf17     }\{\par
341         {\cf19 if} (min_value < 0)\par
342             min_value = divisor;\par
343         {\cf18 int} new_v = std::max(min_value, (({\cf18 int})((({\cf18 int})(v + divisor / 2)) / divisor)) * divisor);\par
344         {\cf19 if} (new_v < (0.9 * ({\cf18 float})v))\par
345             new_v += divisor;\par
346         {\cf19 return} new_v;\par
347     \}\par
348 \par
349     {\cf20 // Features output channels but can be scaled.}\par
350     {\cf18 int} features_output_channels = 1280;\par
351 \par
352     {\cf20 // MobileNetV2 inverted residual settings:}\par
353     {\cf20 // t, c, n, s  (expansion, output channels, repeats, stride)}\par
354     {\cf17 const} std::vector<std::array<int, 4>> inverted_residual_setting = \{\par
355         \{1, 16, 1, 1\},\par
356         \{6, 24, 2, 2\},\par
357         \{6, 32, 3, 2\},\par
358         \{6, 64, 4, 2\},\par
359         \{6, 96, 3, 1\},\par
360         \{6, 160, 3, 2\},\par
361         \{6, 320, 1, 1\},\par
362     \};\par
363 \par
368     {\cf17 class }Conv2dNormActivation : {\cf17 public} torch::nn::Module\par
369     \{\par
370     {\cf17 public}:\par
371         {\cf17 static} {\cf17 constexpr} {\cf18 char} className[] = {\cf22 "Conv2dNormActivation"};\par
372 \par
373         {\cf17 static} {\cf17 inline} torch::Tensor relu6({\cf17 const} torch::Tensor &x)\par
374         \{\par
375             {\cf19 return} torch::clamp(torch::relu(x), 0, 6);\par
376         \}\par
377 \par
378         Conv2dNormActivation({\cf18 int} in_channels,\par
379                              {\cf18 int} out_channels,\par
380                              {\cf18 int} kernel_size = 3,\par
381                              {\cf18 int} stride = 1,\par
382                              {\cf18 int} padding = -1,\par
383                              {\cf18 int} groups = 1)\par
384         \{\par
385             {\cf17 const} {\cf18 int} dilation = 1;\par
386             conv = torch::nn::Sequential();\par
387             {\cf19 if} (padding < 0)\par
388             \{\par
389                 padding = (kernel_size - 1) / 2 * dilation;\par
390             \}\par
391             conv->push_back(torch::nn::Conv2d(\par
392                 torch::nn::Conv2dOptions(in_channels, out_channels, kernel_size)\par
393                     .stride(stride)\par
394                     .padding(padding)\par
395                     .groups(groups)\par
396                     .bias({\cf17 false})));\par
397             conv->push_back(torch::nn::BatchNorm2d(torch::nn::BatchNorm2dOptions(out_channels)));\par
398             conv->push_back(torch::nn::Functional(relu6));\par
399             register_module(className, conv);\par
400         \}\par
401 \par
402         torch::Tensor forward({\cf17 const} torch::Tensor &x)\par
403         \{\par
404             {\cf19 return} conv->forward(x);\par
405         \}\par
406 \par
407     {\cf17 private}:\par
408         torch::nn::Sequential conv\{{\cf17 nullptr}\};\par
409     \};\par
410 \par
415     {\cf17 class }InvertedResidual : {\cf17 public} torch::nn::Module\par
416     \{\par
417     {\cf17 public}:\par
418         {\cf17 static} {\cf17 constexpr} {\cf18 char} className[] = {\cf22 "InvertedResidual"};\par
419 \par
420         InvertedResidual({\cf18 int} inp, {\cf18 int} oup, {\cf18 int} stride, {\cf18 int} expand_ratio)\par
421         \{\par
422             {\cf19 if} ((stride < 1) || (stride > 2))\par
423             \{\par
424                 {\cf19 throw} std::invalid_argument({\cf22 "Stride needs to be 1 or 2."});\par
425             \}\par
426             {\cf17 const} {\cf18 int} hidden_dim = (int)round(inp * expand_ratio);\par
427             use_res_connect = (stride == 1) && (inp == oup);\par
428 \par
429             conv = torch::nn::Sequential();\par
430 \par
431             {\cf19 if} (expand_ratio != 1)\par
432             \{\par
433                 conv->push_back(\par
434                     Conv2dNormActivation(inp,\par
435                                          hidden_dim,\par
436                                          {\cf20 /*kernel_size*/} 1));\par
437             \}\par
438 \par
439             conv->push_back(\par
440                 Conv2dNormActivation(hidden_dim,\par
441                                      hidden_dim,\par
442                                      {\cf20 /*kernel_size=*/}3,\par
443                                      {\cf20 /*stride=*/}stride,\par
444                                      {\cf20 /*padding=*/}-1,\par
445                                      {\cf20 /*groups=*/}hidden_dim));\par
446 \par
447             conv->push_back(torch::nn::Conv2d(\par
448                 torch::nn::Conv2dOptions(hidden_dim, oup,\par
449                                          {\cf20 /*kernel_size=*/}1)\par
450                     .stride(1)\par
451                     .padding(0)\par
452                     .bias({\cf17 false})));\par
453             conv->push_back(torch::nn::BatchNorm2d(torch::nn::BatchNorm2dOptions(oup)));\par
454 \par
455             register_module(className, conv);\par
456         \}\par
457 \par
458         torch::Tensor forward({\cf17 const} torch::Tensor &x)\par
459         \{\par
460             {\cf19 if} (use_res_connect)\par
461             \{\par
462                 {\cf19 return} x + conv->forward(x);\par
463             \}\par
464             {\cf19 else}\par
465             \{\par
466                 {\cf19 return} conv->forward(x);\par
467             \}\par
468         \}\par
469         torch::nn::Sequential conv\{{\cf17 nullptr}\};\par
470         {\cf18 bool} use_res_connect;\par
471     \};\par
472 \};\par
}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid Index\par 
\pard\plain 
{\tc \v Index}
{\field\fldedit {\*\fldinst INDEX \\c2 \\*MERGEFORMAT}{\fldrslt INDEX}}
}
