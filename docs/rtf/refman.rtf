{\rtf1\ansi\ansicpg1252\uc1 \deff0\deflang1033\deflangfe1033
{\fonttbl {\f0\froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}
{\f1\fswiss\fcharset0\fprq2{\*\panose 020b0604020202020204}Arial;}
{\f2\fmodern\fcharset0\fprq1{\*\panose 02070309020205020404}Courier New;}
{\f3\froman\fcharset2\fprq2{\*\panose 05050102010706020507}Symbol;}
}
{\colortbl;\red0\green0\blue0;\red0\green0\blue255;\red0\green255\blue255;\red0\green255\blue0;\red255\green0\blue255;\red255\green0\blue0;\red255\green255\blue0;\red255\green255\blue255;\red0\green0\blue128;\red0\green128\blue128;\red0\green128\blue0;\red128\green0\blue128;\red128\green0\blue0;\red128\green128\blue0;\red128\green128\blue128;\red192\green192\blue192;\red0\green128\blue0;\red96\green64\blue32;\rede0\green128\blue0;\red128\green0\blue0;\red128\green96\blue32;\red0\green32\blue128;\red0\green128\blue128;\red255\green0\blue255;\red0\green0\blue0;\red112\green0\blue112;\red255\green0\blue0;}
{\stylesheet
{\widctlpar\adjustright \fs20\cgrid \snext0 Normal;}
{\paperw11900\paperh16840\margl1800\margr1800\margt1440\margb1440\gutter0\ltrsect}
{\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid \sbasedon0 \snext0 heading 1;}
{\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid \sbasedon0 \snext0 heading 2;}
{\s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid \sbasedon0 \snext0 heading 3;}
{\s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext0 heading 4;}{\*\cs10 \additive Default Paragraph Font;}
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext0 heading 5;}{\*\cs10 \additive Default Paragraph Font;}
{\s15\qc\sb240\sa60\widctlpar\outlinelevel0\adjustright \b\f1\fs32\kerning28\cgrid \sbasedon0 \snext15 Title;}
{\s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid \sbasedon0 \snext16 Subtitle;}
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid \sbasedon0 \snext17 BodyText;}
{\s18\widctlpar\fs22\cgrid \sbasedon0 \snext18 DenseText;}
{\s28\widctlpar\tqc\tx4320\tqr\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext28 header;}
{\s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid \sbasedon0 \snext29 footer;}
{\s30\li360\sa60\sb120\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext30 GroupHeader;}
{\s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext41 Code Example 0;}
{\s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext42 Code Example 1;}
{\s42\li720\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext43 Code Example 2;}
{\s43\li1080\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext44 Code Example 3;}
{\s44\li1440\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext45 Code Example 4;}
{\s45\li1800\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext46 Code Example 5;}
{\s46\li2160\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext47 Code Example 6;}
{\s47\li2520\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext48 Code Example 7;}
{\s48\li2880\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext49 Code Example 8;}
{\s49\li3240\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext50 Code Example 9;}
{\s50\li3600\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext51 Code Example 10;}
{\s51\li3960\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext52 Code Example 11;}
{\s52\li4320\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext53 Code Example 12;}
{\s53\li4680\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext53 Code Example 13;}
{\s60\li0\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext61 List Continue 0;}
{\s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext62 List Continue 1;}
{\s62\li720\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext63 List Continue 2;}
{\s63\li1080\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext64 List Continue 3;}
{\s64\li1440\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext65 List Continue 4;}
{\s65\li1800\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext66 List Continue 5;}
{\s66\li2160\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext67 List Continue 6;}
{\s67\li2520\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext68 List Continue 7;}
{\s68\li2880\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext69 List Continue 8;}
{\s69\li3240\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext70 List Continue 9;}
{\s70\li3600\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext71 List Continue 10;}
{\s71\li3960\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext72 List Continue 11;}
{\s72\li4320\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext73 List Continue 12;}
{\s73\li4680\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext73 List Continue 13;}
{\s80\li0\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext81 DescContinue 0;}
{\s81\li360\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext82 DescContinue 1;}
{\s82\li720\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext83 DescContinue 2;}
{\s83\li1080\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext84 DescContinue 3;}
{\s84\li1440\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext85 DescContinue 4;}
{\s85\li1800\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext86 DescContinue 5;}
{\s86\li2160\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext87 DescContinue 6;}
{\s87\li2520\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext88 DescContinue 7;}
{\s88\li2880\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext89 DescContinue 8;}
{\s89\li3240\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext90 DescContinue 9;}
{\s90\li3600\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext91 DescContinue 10;}
{\s91\li3960\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext92 DescContinue 11;}
{\s92\li4320\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext93 DescContinue 12;}
{\s93\li4680\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext93 DescContinue 13;}
{\s100\li0\sa30\sb30\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext101 LatexTOC 0;}
{\s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext102 LatexTOC 1;}
{\s102\li720\sa24\sb24\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext103 LatexTOC 2;}
{\s103\li1080\sa21\sb21\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext104 LatexTOC 3;}
{\s104\li1440\sa18\sb18\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext105 LatexTOC 4;}
{\s105\li1800\sa15\sb15\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext106 LatexTOC 5;}
{\s106\li2160\sa12\sb12\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext107 LatexTOC 6;}
{\s107\li2520\sa9\sb9\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext108 LatexTOC 7;}
{\s108\li2880\sa6\sb6\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext109 LatexTOC 8;}
{\s109\li3240\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext110 LatexTOC 9;}
{\s110\li3600\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext111 LatexTOC 10;}
{\s111\li3960\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext112 LatexTOC 11;}
{\s112\li4320\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext113 LatexTOC 12;}
{\s113\li4680\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext113 LatexTOC 13;}
{\s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext121 \sautoupd List Bullet 0;}
{\s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext122 \sautoupd List Bullet 1;}
{\s122\fi-360\li1080\widctlpar\jclisttab\tx1080{\*\pn \pnlvlbody\ilvl0\ls3\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext123 \sautoupd List Bullet 2;}
{\s123\fi-360\li1440\widctlpar\jclisttab\tx1440{\*\pn \pnlvlbody\ilvl0\ls4\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext124 \sautoupd List Bullet 3;}
{\s124\fi-360\li1800\widctlpar\jclisttab\tx1800{\*\pn \pnlvlbody\ilvl0\ls5\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext125 \sautoupd List Bullet 4;}
{\s125\fi-360\li2160\widctlpar\jclisttab\tx2160{\*\pn \pnlvlbody\ilvl0\ls6\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext126 \sautoupd List Bullet 5;}
{\s126\fi-360\li2520\widctlpar\jclisttab\tx2520{\*\pn \pnlvlbody\ilvl0\ls7\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext127 \sautoupd List Bullet 6;}
{\s127\fi-360\li2880\widctlpar\jclisttab\tx2880{\*\pn \pnlvlbody\ilvl0\ls8\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext128 \sautoupd List Bullet 7;}
{\s128\fi-360\li3240\widctlpar\jclisttab\tx3240{\*\pn \pnlvlbody\ilvl0\ls9\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext129 \sautoupd List Bullet 8;}
{\s129\fi-360\li3600\widctlpar\jclisttab\tx3600{\*\pn \pnlvlbody\ilvl0\ls10\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext130 \sautoupd List Bullet 9;}
{\s130\fi-360\li3960\widctlpar\jclisttab\tx3960{\*\pn \pnlvlbody\ilvl0\ls11\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext131 \sautoupd List Bullet 10;}
{\s131\fi-360\li4320\widctlpar\jclisttab\tx4320{\*\pn \pnlvlbody\ilvl0\ls12\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext132 \sautoupd List Bullet 11;}
{\s132\fi-360\li4680\widctlpar\jclisttab\tx4680{\*\pn \pnlvlbody\ilvl0\ls13\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext133 \sautoupd List Bullet 12;}
{\s133\fi-360\li5040\widctlpar\jclisttab\tx5040{\*\pn \pnlvlbody\ilvl0\ls14\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext133 \sautoupd List Bullet 13;}
{\s140\fi-360\li360\widctlpar\fs20\cgrid \sbasedon0 \snext141 \sautoupd List Enum 0;}
{\s141\fi-360\li720\widctlpar\fs20\cgrid \sbasedon0 \snext142 \sautoupd List Enum 1;}
{\s142\fi-360\li1080\widctlpar\fs20\cgrid \sbasedon0 \snext143 \sautoupd List Enum 2;}
{\s143\fi-360\li1440\widctlpar\fs20\cgrid \sbasedon0 \snext144 \sautoupd List Enum 3;}
{\s144\fi-360\li1800\widctlpar\fs20\cgrid \sbasedon0 \snext145 \sautoupd List Enum 4;}
{\s145\fi-360\li2160\widctlpar\fs20\cgrid \sbasedon0 \snext146 \sautoupd List Enum 5;}
{\s146\fi-360\li2520\widctlpar\fs20\cgrid \sbasedon0 \snext147 \sautoupd List Enum 6;}
{\s147\fi-360\li2880\widctlpar\fs20\cgrid \sbasedon0 \snext148 \sautoupd List Enum 7;}
{\s148\fi-360\li3240\widctlpar\fs20\cgrid \sbasedon0 \snext149 \sautoupd List Enum 8;}
{\s149\fi-360\li3600\widctlpar\fs20\cgrid \sbasedon0 \snext150 \sautoupd List Enum 9;}
{\s150\fi-360\li3960\widctlpar\fs20\cgrid \sbasedon0 \snext151 \sautoupd List Enum 10;}
{\s151\fi-360\li4320\widctlpar\fs20\cgrid \sbasedon0 \snext152 \sautoupd List Enum 11;}
{\s152\fi-360\li4680\widctlpar\fs20\cgrid \sbasedon0 \snext153 \sautoupd List Enum 12;}
{\s153\fi-360\li5040\widctlpar\fs20\cgrid \sbasedon0 \snext153 \sautoupd List Enum 13;}
}
{\info 
{\title {\comment Mobilenet with Libtorch }Mobilenet with Libtorch}
{\comment Generated by doxygen 1.9.8.}
}\pard\plain 
\sectd\pgnlcrm
{\footer \s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid {\chpgn}}
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
\vertalc\qc\par\par\par\par\par\par\par
\pard\plain \s15\qc\sb240\sa60\widctlpar\outlinelevel0\adjustright \b\f1\fs32\kerning28\cgrid 
{\field\fldedit {\*\fldinst TITLE \\*MERGEFORMAT}{\fldrslt Mobilenet with Libtorch}}\par
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
\par
\par\par\par\par\par\par\par\par\par\par\par\par
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
{\field\fldedit {\*\fldinst AUTHOR \\*MERGEFORMAT}{\fldrslt AUTHOR}}\par
Version \par\page\page\vertalt
\pard\plain 
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid Table of Contents\par
\pard\plain \par
{\field\fldedit {\*\fldinst TOC \\f \\*MERGEFORMAT}{\fldrslt Table of contents}}\par
\pard\plain 
\sect \sbkpage \pgndec \pgnrestart
\sect \sectd \sbknone
{\footer \s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid {\chpgn}}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
\par \pard\plain 
\pard\plain \s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
MobileNetV2 libtorch\par \pard\plain 
{\tc\tcl1 \v MobileNetV2 libtorch}
{\xe \v MobileNetV2 libtorch}
{\bkmkstart AAAAAAAABC}
{\bkmkend AAAAAAAABC}
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\bkmkstart AAAAAAAABD}
{\bkmkend AAAAAAAABD}
C++ version of {\b MobileNetV2} using libtorch which can import the pre-trained weights from torchvision.\par
Importing the weights instead of using the JIT has the advantage that one can do transfer learning also on an edge device, for example, to adapt to different situations locally.\par
This implementation follows very closely the {\f2 torchvision implementation of mobilenet v2}.\par
Mobilenet is described {\f2 here}.\par
Then simply include {\f2 {\b mobilenet_v2.h}}  into your own project.\par
{\pard\plain \s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid {\tc\tcl1 Credit} \par}
(C) 2025 {\f2 Bernd Porr}, GPLv3 \par
}}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Hierarchical Index\par \pard\plain 
{\tc \v Hierarchical Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
Class Hierarchy\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid This inheritance list is sorted roughly, but not completely, alphabetically:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
torch::nn::Module
{
\par
\pard\plain \s102\li720\sa24\sb24\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
Conv2dNormActivation\tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAB \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
InvertedResidual\tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAH \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
MobileNetV2\tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAN \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
}\par
}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Class Index\par \pard\plain 
{\tc \v Class Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
Class List\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid Here are the classes, structs, unions and interfaces with brief descriptions:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
{\b {\b Conv2dNormActivation} ({\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Module which performs Convolution, Batch Norm and Relu6 })} \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAB \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b InvertedResidual} ({\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Inverted residual Converted from {\f2 https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py#L19} })} \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAH \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b MobileNetV2} ({\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Implementation of {\b MobileNetV2} as done in py-torchvision See: // {\f2 https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py#L66} })} \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAN \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
\par}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
File Index\par \pard\plain 
{\tc \v File Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
File List\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid Here is a list of all documented files with brief descriptions:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
{\b {\b mobilenet_v2.h} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAA \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
\par}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Class Documentation{\tc \v Class Documentation}
\par \pard\plain 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
Conv2dNormActivation Struct Reference\par \pard\plain 
{\tc\tcl2 \v Conv2dNormActivation}
{\xe \v Conv2dNormActivation}
{\bkmkstart AAAAAAAAAB}
{\bkmkend AAAAAAAAAB}
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Module which performs Convolution, Batch Norm and Relu6. }}\par
{
{\f2 #include <mobilenet_v2.h>}}\par
Inheritance diagram for Conv2dNormActivation:{
\pard\plain 
\par\pard \qc {\field\flddirty {\*\fldinst INCLUDEPICTURE "structConv2dNormActivation__inherit__graph.png" \\d \\*MERGEFORMAT}{\fldrslt IMAGE}}\par
}
\par
Collaboration diagram for Conv2dNormActivation:{
\pard\plain 
\par\pard \qc {\field\flddirty {\*\fldinst INCLUDEPICTURE "structConv2dNormActivation__coll__graph.png" \\d \\*MERGEFORMAT}{\fldrslt IMAGE}}\par
}
\par
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Public Member Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

{\b Conv2dNormActivation} (int in_channels, int out_channels, int kernel_size=3, int stride=1, int padding=-1, int groups=1){\bkmkstart AAAAAAAAAC}
{\bkmkend AAAAAAAAAC}
\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

torch::Tensor {\b forward} (const torch::Tensor &x){\bkmkstart AAAAAAAAAD}
{\bkmkend AAAAAAAAAD}
\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Static Public Member Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

static torch::Tensor {\b relu6} (const torch::Tensor &x){\bkmkstart AAAAAAAAAE}
{\bkmkend AAAAAAAAAE}
\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Public Attributes\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

torch::nn::Sequential {\b conv} \{nullptr\}{\bkmkstart AAAAAAAAAF}
{\bkmkend AAAAAAAAAF}
\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Static Public Attributes\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

static constexpr char {\b className} [] = "Conv2dNormActivation"{\bkmkstart AAAAAAAAAG}
{\bkmkend AAAAAAAAAG}
\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Module which performs Convolution, Batch Norm and Relu6. \par
}

{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
See {\f2 https://github.com/pytorch/vision/blob/main/torchvision/ops/misc.py#L126} \par
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
The documentation for this struct was generated from the following file:{\par
\pard\plain \s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
mobilenet_v2.h\par
}\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
InvertedResidual Struct Reference\par \pard\plain 
{\tc\tcl2 \v InvertedResidual}
{\xe \v InvertedResidual}
{\bkmkstart AAAAAAAAAH}
{\bkmkend AAAAAAAAAH}
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Inverted residual Converted from {\f2 https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py#L19}. }}\par
{
{\f2 #include <mobilenet_v2.h>}}\par
Inheritance diagram for InvertedResidual:{
\pard\plain 
\par\pard \qc {\field\flddirty {\*\fldinst INCLUDEPICTURE "structInvertedResidual__inherit__graph.png" \\d \\*MERGEFORMAT}{\fldrslt IMAGE}}\par
}
\par
Collaboration diagram for InvertedResidual:{
\pard\plain 
\par\pard \qc {\field\flddirty {\*\fldinst INCLUDEPICTURE "structInvertedResidual__coll__graph.png" \\d \\*MERGEFORMAT}{\fldrslt IMAGE}}\par
}
\par
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Public Member Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

{\b InvertedResidual} (int inp, int oup, int stride, int expand_ratio){\bkmkstart AAAAAAAAAI}
{\bkmkend AAAAAAAAAI}
\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

torch::Tensor {\b forward} (const torch::Tensor &x){\bkmkstart AAAAAAAAAJ}
{\bkmkend AAAAAAAAAJ}
\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Public Attributes\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

torch::nn::Sequential {\b conv} \{nullptr\}{\bkmkstart AAAAAAAAAK}
{\bkmkend AAAAAAAAAK}
\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

bool {\b use_res_connect}{\bkmkstart AAAAAAAAAL}
{\bkmkend AAAAAAAAAL}
\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Static Public Attributes\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

static constexpr char {\b className} [] = "InvertedResidual"{\bkmkstart AAAAAAAAAM}
{\bkmkend AAAAAAAAAM}
\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Inverted residual Converted from {\f2 https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py#L19}. \par
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
The documentation for this struct was generated from the following file:{\par
\pard\plain \s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
mobilenet_v2.h\par
}\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
MobileNetV2 Struct Reference\par \pard\plain 
{\tc\tcl2 \v MobileNetV2}
{\xe \v MobileNetV2}
{\bkmkstart AAAAAAAAAN}
{\bkmkend AAAAAAAAAN}
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Implementation of {\b MobileNetV2} as done in py-torchvision See: // {\f2 https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py#L66}. }}\par
{
{\f2 #include <mobilenet_v2.h>}}\par
Inheritance diagram for MobileNetV2:{
\pard\plain 
\par\pard \qc {\field\flddirty {\*\fldinst INCLUDEPICTURE "structMobileNetV2__inherit__graph.png" \\d \\*MERGEFORMAT}{\fldrslt IMAGE}}\par
}
\par
Collaboration diagram for MobileNetV2:{
\pard\plain 
\par\pard \qc {\field\flddirty {\*\fldinst INCLUDEPICTURE "structMobileNetV2__coll__graph.png" \\d \\*MERGEFORMAT}{\fldrslt IMAGE}}\par
}
\par
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Public Member Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b MobileNetV2} (int num_classes=1000, float width_mult=1.0f, int round_nearest=8, float dropout=0.2)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Construct a new {\b MobileNetV2} object If you want to load the weights from torchvision into the classifier use the default values for the parameters. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b getNinputChannels4Classifier} () const\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Gets the number of input channels for the classfier This will make it easy to replace the classifier with anything the user wants by creating their own torch::nn::Sequential() for the classifier. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
torch::Tensor {\b forward} (torch::Tensor x)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Performs the forward pass. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

void {\b initialize_weights} (){\bkmkstart AAAAAAAAAO}
{\bkmkend AAAAAAAAAO}
\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Initialize conv/bn/linear similar to torchvision defaults. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

std::string {\b ourkey2torchvision} (std::string k) const{\bkmkstart AAAAAAAAAP}
{\bkmkend AAAAAAAAAP}
\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
void {\b load_weights} (std::string pt)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Loads a .pt weight file containing a dic with key/parameter pairs See {\f2 https://github.com/pytorch/pytorch/issues/36577}. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

int {\b make_divisible} (int v, int divisor=8, int min_value=-1) const{\bkmkstart AAAAAAAAAQ}
{\bkmkend AAAAAAAAAQ}
\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Static Public Member Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
static torch::Tensor {\b preprocess} (cv::Mat img, bool resizeOnly=false)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Preprocessing of an openCV image for inference or learning The images are resized to 256x256, followed by a central crop of 224x224. }{
}\par
}\par}
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Public Attributes\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

torch::nn::Sequential {\b features} \{nullptr\}{\bkmkstart AAAAAAAAAR}
{\bkmkend AAAAAAAAAR}
\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

torch::nn::Sequential {\b classifier} \{nullptr\}{\bkmkstart AAAAAAAAAS}
{\bkmkend AAAAAAAAAS}
\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

int {\b features_output_channels} = 1280{\bkmkstart AAAAAAAAAT}
{\bkmkend AAAAAAAAAT}
\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
const std::vector< std::array< int, 4 > > {\b inverted_residual_setting}\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Static Public Attributes\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

static constexpr char {\b featuresModuleName} [] = "features"{\bkmkstart AAAAAAAAAU}
{\bkmkend AAAAAAAAAU}
\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
static constexpr char {\b classifierModuleName} [] = "classifier"\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Name of the classifier module. }{
}\par
}\par}
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Implementation of {\b MobileNetV2} as done in py-torchvision See: // {\f2 https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py#L66}. \par
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Constructor & Destructor Documentation\par
\pard\plain 
{\xe \v MobileNetV2\:MobileNetV2}
{\xe \v MobileNetV2\:MobileNetV2}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
MobileNetV2::MobileNetV2 (int  {\i num_classes} = {\f2 1000}, float  {\i width_mult} = {\f2 1.0f}, int  {\i round_nearest} = {\f2 8}, float  {\i dropout} = {\f2 0.2}){\f2 [inline]}}}
\par
{\bkmkstart AAAAAAAAAV}
{\bkmkend AAAAAAAAAV}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Construct a new {\b MobileNetV2} object If you want to load the weights from torchvision into the classifier use the default values for the parameters. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\par
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i num_classes} \cell }{Number of classes \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i width_mult} \cell }{Width multiplier - adjusts number of channels in each layer by this amount \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i round_nearest} \cell }{Round the number of channels in each layer to be a multiple of this number \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i dropout} \cell }{Dropout probability for the dropout layer in the classifier \cell }
{\row }
}
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Member Function Documentation\par
\pard\plain 
{\xe \v forward\:MobileNetV2}
{\xe \v MobileNetV2\:forward}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
torch::Tensor MobileNetV2::forward (torch::Tensor  {\i x}){\f2 [inline]}}}
\par
{\bkmkstart AAAAAAAAAW}
{\bkmkend AAAAAAAAAW}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Performs the forward pass. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\par
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i x} \cell }{The batch of input images. \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
torch::Tensor The category scores for the different labels. \par
}}}}
{\xe \v getNinputChannels4Classifier\:MobileNetV2}
{\xe \v MobileNetV2\:getNinputChannels4Classifier}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
int MobileNetV2::getNinputChannels4Classifier () const{\f2 [inline]}}}
\par
{\bkmkstart AAAAAAAAAX}
{\bkmkend AAAAAAAAAX}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Gets the number of input channels for the classfier This will make it easy to replace the classifier with anything the user wants by creating their own torch::nn::Sequential() for the classifier. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
int The number of intput channels to the classifer class "classfier". \par
}}}}
{\xe \v load_weights\:MobileNetV2}
{\xe \v MobileNetV2\:load_weights}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
void MobileNetV2::load_weights (std::string  {\i pt}){\f2 [inline]}}}
\par
{\bkmkstart AAAAAAAAAY}
{\bkmkend AAAAAAAAAY}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Loads a .pt weight file containing a dic with key/parameter pairs See {\f2 https://github.com/pytorch/pytorch/issues/36577}. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\par
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i pt} \cell }{filename of the .pt weight file \cell }
{\row }
}
}}
{\xe \v preprocess\:MobileNetV2}
{\xe \v MobileNetV2\:preprocess}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
static torch::Tensor MobileNetV2::preprocess (cv::Mat  {\i img}, bool  {\i resizeOnly} = {\f2 false}){\f2 [inline]}, {\f2 [static]}}}
\par
{\bkmkstart AAAAAAAAAZ}
{\bkmkend AAAAAAAAAZ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Preprocessing of an openCV image for inference or learning The images are resized to 256x256, followed by a central crop of 224x224. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Finally the values are first rescaled to [0.0, 1.0] and then normalized using mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225].\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i img} \cell }{8bit BGR openCV image with an aspect ratio of 1:1 \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i resizeOnly} \cell }{If true the image is only resized to 224x224 but not cropped. Default: false. \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
torch::Tensor The image as a tensor ready to be used for inference and learning. \par
}}}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Member Data Documentation\par
\pard\plain 
{\xe \v classifierModuleName\:MobileNetV2}
{\xe \v MobileNetV2\:classifierModuleName}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
constexpr char MobileNetV2::classifierModuleName[] = "classifier"{\f2 [static]}, {\f2 [constexpr]}}}
\par
{\bkmkstart AAAAAAAABA}
{\bkmkend AAAAAAAABA}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Name of the classifier module. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
The name of the classifier module is needed whne replacing the default classifier. \par
}}
{\xe \v inverted_residual_setting\:MobileNetV2}
{\xe \v MobileNetV2\:inverted_residual_setting}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
const std::vector<std::array<int, 4> > MobileNetV2::inverted_residual_setting}}
\par
{\bkmkstart AAAAAAAABB}
{\bkmkend AAAAAAAABB}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\b Initial value:}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid = \{\par
        \{1, 16, 1, 1\},\par
        \{6, 24, 2, 2\},\par
        \{6, 32, 3, 2\},\par
        \{6, 64, 4, 2\},\par
        \{6, 96, 3, 1\},\par
        \{6, 160, 3, 2\},\par
        \{6, 320, 1, 1\},\par
    \}\par
}
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
The documentation for this struct was generated from the following file:{\par
\pard\plain \s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
mobilenet_v2.h\par
}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
File Documentation{\tc \v File Documentation}
\par \pard\plain 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
mobilenet_v2.h\par \pard\plain 
{\bkmkstart AAAAAAAAAA}
{\bkmkend AAAAAAAAAA}
{
\pard\plain \s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 1 {\cf21 #pragma once}\par
2 \par
3 {\cf21 #include <torch/torch.h>}\par
4 {\cf21 #include <vector>}\par
5 {\cf21 #include <algorithm>}\par
6 {\cf21 #include <fstream>}\par
7 {\cf21 #include <string>}\par
8 {\cf21 #include <regex>}\par
9 {\cf21 #include <filesystem>}\par
10 {\cf21 #include <iostream>}\par
11 {\cf21 #include <system_error>}\par
12 {\cf21 #include <opencv2/opencv.hpp>}\par
13 \par
14 {\cf20 /***}\par
15 {\cf20  * MobileNetV2 C++ Implementation (LibTorch)}\par
16 {\cf20  * Which is able to load the pre-trained weights from torchvision}\par
17 {\cf20  * (c) 2025 Bernd Porr, GPLv3}\par
18 {\cf20  ***/}\par
19 \par
20 {\cf21 #ifdef NDEBUG}\par
21 {\cf17 constexpr} {\cf18 bool} debugOutput = {\cf17 false};\par
22 {\cf21 #else}\par
23 {\cf17 constexpr} {\cf18 bool} debugOutput = {\cf17 true};\par
24 {\cf21 #endif}\par
25 \par
30 {\cf17 struct }Conv2dNormActivation : torch::nn::Module\par
31 \{\par
32     torch::nn::Sequential conv\{{\cf17 nullptr}\};\par
33     {\cf17 static} {\cf17 constexpr} {\cf18 char} className[] = {\cf22 "Conv2dNormActivation"};\par
34 \par
35     {\cf17 static} {\cf17 inline} torch::Tensor relu6({\cf17 const} torch::Tensor &x)\par
36     \{\par
37         {\cf19 return} torch::clamp(torch::relu(x), 0, 6);\par
38     \}\par
39 \par
40     Conv2dNormActivation({\cf18 int} in_channels,\par
41                          {\cf18 int} out_channels,\par
42                          {\cf18 int} kernel_size = 3,\par
43                          {\cf18 int} stride = 1,\par
44                          {\cf18 int} padding = -1,\par
45                          {\cf18 int} groups = 1)\par
46     \{\par
47         {\cf17 const} {\cf18 int} dilation = 1;\par
48         conv = torch::nn::Sequential();\par
49         {\cf19 if} (padding < 0)\par
50         \{\par
51             padding = (kernel_size - 1) / 2 * dilation;\par
52         \}\par
53         conv->push_back(torch::nn::Conv2d(\par
54             torch::nn::Conv2dOptions(in_channels, out_channels, kernel_size)\par
55                 .stride(stride)\par
56                 .padding(padding)\par
57                 .groups(groups)\par
58                 .bias({\cf17 false})));\par
59         conv->push_back(torch::nn::BatchNorm2d(torch::nn::BatchNorm2dOptions(out_channels)));\par
60         conv->push_back(torch::nn::Functional(relu6));\par
61         register_module(className, conv);\par
62     \}\par
63 \par
64     torch::Tensor forward({\cf17 const} torch::Tensor &x)\par
65     \{\par
66         {\cf19 return} conv->forward(x);\par
67     \}\par
68 \};\par
69 \par
74 {\cf17 struct }InvertedResidual : torch::nn::Module\par
75 \{\par
76     torch::nn::Sequential conv\{{\cf17 nullptr}\};\par
77     {\cf18 bool} use_res_connect;\par
78     {\cf17 static} {\cf17 constexpr} {\cf18 char} className[] = {\cf22 "InvertedResidual"};\par
79 \par
80     InvertedResidual({\cf18 int} inp, {\cf18 int} oup, {\cf18 int} stride, {\cf18 int} expand_ratio)\par
81     \{\par
82         {\cf19 if} ((stride < 1) || (stride > 2))\par
83         \{\par
84             {\cf19 throw} std::invalid_argument({\cf22 "Stride needs to be 1 or 2."});\par
85         \}\par
86         {\cf17 const} {\cf18 int} hidden_dim = (int)round(inp * expand_ratio);\par
87         use_res_connect = (stride == 1) && (inp == oup);\par
88 \par
89         conv = torch::nn::Sequential();\par
90 \par
91         {\cf19 if} (expand_ratio != 1)\par
92         \{\par
93             conv->push_back(\par
94                 Conv2dNormActivation(inp,\par
95                                      hidden_dim,\par
96                                      {\cf20 /*kernel_size*/} 1));\par
97         \}\par
98 \par
99         conv->push_back(\par
100             Conv2dNormActivation(hidden_dim,\par
101                                  hidden_dim,\par
102                                  {\cf20 /*kernel_size=*/}3,\par
103                                  {\cf20 /*stride=*/}stride,\par
104                                  {\cf20 /*padding=*/}-1,\par
105                                  {\cf20 /*groups=*/}hidden_dim));\par
106 \par
107         conv->push_back(torch::nn::Conv2d(\par
108             torch::nn::Conv2dOptions(hidden_dim, oup,\par
109                                      {\cf20 /*kernel_size=*/}1)\par
110                 .stride(1)\par
111                 .padding(0)\par
112                 .bias({\cf17 false})));\par
113         conv->push_back(torch::nn::BatchNorm2d(torch::nn::BatchNorm2dOptions(oup)));\par
114 \par
115         register_module(className, conv);\par
116     \}\par
117 \par
118     torch::Tensor forward({\cf17 const} torch::Tensor &x)\par
119     \{\par
120         {\cf19 if} (use_res_connect)\par
121         \{\par
122             {\cf19 return} x + conv->forward(x);\par
123         \}\par
124         {\cf19 else}\par
125         \{\par
126             {\cf19 return} conv->forward(x);\par
127         \}\par
128     \}\par
129 \};\par
130 \par
135 {\cf17 struct }MobileNetV2 : torch::nn::Module\par
136 \{\par
137     torch::nn::Sequential features\{{\cf17 nullptr}\};\par
138     torch::nn::Sequential classifier\{{\cf17 nullptr}\}; {\cf20 // Dropout + Linear}\par
139     {\cf18 int} features_output_channels = 1280;\par
140 \par
141     {\cf20 // MobileNetV2 inverted residual settings:}\par
142     {\cf20 // t, c, n, s  (expansion, output channels, repeats, stride)}\par
143     {\cf17 const} std::vector<std::array<int, 4>> inverted_residual_setting = \{\par
144         \{1, 16, 1, 1\},\par
145         \{6, 24, 2, 2\},\par
146         \{6, 32, 3, 2\},\par
147         \{6, 64, 4, 2\},\par
148         \{6, 96, 3, 1\},\par
149         \{6, 160, 3, 2\},\par
150         \{6, 320, 1, 1\},\par
151     \};\par
152 \par
153     {\cf20 // Module name of the feature detector.}\par
154     {\cf17 static} {\cf17 constexpr} {\cf18 char} featuresModuleName[] = {\cf22 "features"};\par
155 \par
161     {\cf17 static} {\cf17 constexpr} {\cf18 char} classifierModuleName[] = {\cf22 "classifier"};\par
162 \par
173     MobileNetV2({\cf18 int} num_classes = 1000, {\cf18 float} width_mult = 1.0f, {\cf18 int} round_nearest = 8, {\cf18 float} dropout = 0.2)\par
174     \{\par
175         {\cf18 int} input_channels = 32;\par
176         input_channels = make_divisible(input_channels * width_mult, round_nearest);\par
177         features_output_channels = make_divisible(features_output_channels * std::max(1.0f, width_mult), round_nearest);\par
178 \par
179         features = torch::nn::Sequential();\par
180 \par
181         features->push_back(\par
182             Conv2dNormActivation(3,\par
183                                  input_channels,\par
184                                  {\cf20 /*kernel_size=*/}3,\par
185                                  {\cf20 /*stride =*/}2));\par
186 \par
187         {\cf20 // inverted residual blocks}\par
188         {\cf19 for} ({\cf17 const} {\cf17 auto} &cfg : inverted_residual_setting)\par
189         \{\par
190             {\cf17 const} {\cf18 int} t = cfg[0];\par
191             {\cf17 const} {\cf18 int} c = cfg[1];\par
192             {\cf17 const} {\cf18 int} n = cfg[2];\par
193             {\cf17 const} {\cf18 int} s = cfg[3];\par
194 \par
195             {\cf18 int} output_channel = make_divisible(c * width_mult, round_nearest);\par
196             {\cf19 for} ({\cf18 int} i = 0; i < n; ++i)\par
197             \{\par
198                 {\cf17 const} {\cf18 int} stride = (i == 0) ? s : 1;\par
199                 features->push_back(\par
200                     InvertedResidual(input_channels, output_channel, stride, t));\par
201                 input_channels = output_channel;\par
202             \}\par
203         \}\par
204 \par
205         features->push_back(\par
206             Conv2dNormActivation(input_channels,\par
207                                  features_output_channels,\par
208                                  {\cf20 /*kernel_size=*/}1));\par
209 \par
210         register_module(featuresModuleName, features);\par
211 \par
212         {\cf20 // classifier: Dropout + Linear}\par
213         classifier = torch::nn::Sequential();\par
214         classifier->push_back(torch::nn::Dropout(torch::nn::DropoutOptions(dropout)));\par
215         classifier->push_back(torch::nn::Linear(torch::nn::LinearOptions(features_output_channels, num_classes)));\par
216         register_module(classifierModuleName, classifier);\par
217     \}\par
218 \par
226     {\cf18 int} getNinputChannels4Classifier(){\cf17  const}\par
227 {\cf17     }\{\par
228         {\cf19 return} features_output_channels;\par
229     \}\par
230 \par
237     torch::Tensor forward(torch::Tensor x)\par
238     \{\par
239         x = features->forward(x);\par
240         {\cf17 const} torch::nn::functional::AdaptiveAvgPool2dFuncOptions &ar = torch::nn::functional::AdaptiveAvgPool2dFuncOptions(\{1, 1\});\par
241         x = torch::nn::functional::adaptive_avg_pool2d(x, ar);\par
242         x = torch::flatten(x, 1);\par
243         x = classifier->forward(x);\par
244         {\cf19 return} x;\par
245     \}\par
246 \par
250     {\cf18 void} initialize_weights()\par
251     \{\par
252         {\cf19 for} ({\cf17 auto} &module : modules({\cf20 /*include_self=*/}{\cf17 false}))\par
253         \{\par
254             {\cf19 if} ({\cf17 auto} M = {\cf17 dynamic_cast<}torch::nn::Conv2dImpl *{\cf17 >}(module.get()))\par
255             \{\par
256                 torch::nn::init::kaiming_normal_(M->weight, {\cf20 /*a=*/}0, torch::kFanOut, torch::kReLU);\par
257                 {\cf19 if} (M->options.bias())\par
258                     torch::nn::init::zeros_(M->bias);\par
259             \}\par
260             {\cf19 else} {\cf19 if} ({\cf17 auto} M = {\cf17 dynamic_cast<}torch::nn::BatchNorm2dImpl *{\cf17 >}(module.get()))\par
261             \{\par
262                 torch::nn::init::ones_(M->weight);\par
263                 torch::nn::init::zeros_(M->bias);\par
264             \}\par
265             {\cf19 else} {\cf19 if} ({\cf17 auto} M = {\cf17 dynamic_cast<}torch::nn::LinearImpl *{\cf17 >}(module.get()))\par
266             \{\par
267                 torch::nn::init::normal_(M->weight, 0.0, 0.01);\par
268                 torch::nn::init::zeros_(M->bias);\par
269             \}\par
270         \}\par
271     \}\par
272 \par
273     std::string ourkey2torchvision(std::string k){\cf17  const}\par
274 {\cf17     }\{\par
275         {\cf20 // called simply "conv" in the weights file}\par
276         k = std::regex_replace(k, std::regex(InvertedResidual::className), {\cf22 "conv"});\par
277         {\cf20 // not used at all in the weights file}\par
278         {\cf17 const} std::string r = std::string(Conv2dNormActivation::className) + {\cf22 "\\\\."};\par
279         k = std::regex_replace(k, std::regex(r), {\cf22 ""});\par
280         {\cf19 return} k;\par
281     \}\par
282 \par
289     {\cf18 void} load_weights(std::string pt)\par
290     \{\par
291         std::ifstream input(pt, std::ios::binary);\par
292         input.exceptions(input.failbit);\par
293         std::vector<char> bytes(\par
294             (std::istreambuf_iterator<char>(input)),\par
295             (std::istreambuf_iterator<char>()));\par
296         input.close();\par
297         {\cf17 const} c10::Dict<c10::IValue, c10::IValue> weights = torch::pickle_load(bytes).toGenericDict();\par
298         {\cf19 if} (debugOutput)\par
299         \{\par
300             std::cerr << {\cf22 "Parameters we have in this model here: "} << std::endl;\par
301             {\cf19 for} ({\cf17 auto} {\cf17 const} &m : named_parameters())\par
302             \{\par
303                 {\cf17 auto} k = ourkey2torchvision(m.key());\par
304                 std::cerr << m.key() << {\cf22 "->"} << k << {\cf22 ": "} << m.value().sizes() << std::endl;\par
305             \}\par
306             std::cerr << {\cf22 "Named buffers we have in this model here: "} << std::endl;\par
307             {\cf19 for} ({\cf17 const} {\cf17 auto} &b : named_buffers())\par
308             \{\par
309                 {\cf17 auto} k = ourkey2torchvision(b.key());\par
310                 std::cout << b.key() << {\cf22 "->"} << k << {\cf22 ": "} << b.value().sizes() << std::endl;\par
311             \}\par
312             std::cerr << {\cf22 "Parameters we have in the weight file "} << pt << {\cf22 ":"} << std::endl;\par
313             {\cf19 for} ({\cf17 auto} {\cf17 const} &w : weights)\par
314             \{\par
315                 std::cerr << w.key() << {\cf22 ": "} << w.value().toTensor().sizes() << std::endl;\par
316             \}\par
317         \}\par
318         torch::NoGradGuard no_grad;\par
319         {\cf19 if} (debugOutput)\par
320             std::cerr << {\cf22 "Loading weights"} << std::endl;\par
321         {\cf19 for} ({\cf17 auto} &m : named_parameters())\par
322         \{\par
323             {\cf17 const} std::string model_key = m.key();\par
324             {\cf17 const} std::string model_key4torchvision = ourkey2torchvision(model_key);\par
325             {\cf19 if} (debugOutput)\par
326                 std::cerr << {\cf22 "Searching for: "} << model_key4torchvision << {\cf22 ": "} << m.value().sizes() << std::endl;\par
327             {\cf18 bool} foundit = {\cf17 false};\par
328             {\cf19 for} ({\cf17 auto} {\cf17 const} &w : weights)\par
329             \{\par
330                 {\cf19 if} (model_key4torchvision == w.key())\par
331                 \{\par
332                     {\cf19 if} (debugOutput)\par
333                         std::cerr << {\cf22 "Found it: "} << w.key() << std::endl;\par
334                     m.value().copy_(w.value().toTensor());\par
335                     foundit = {\cf17 true};\par
336                     {\cf19 break};\par
337                 \}\par
338             \}\par
339             {\cf19 if} (!foundit)\par
340                 std::cerr << {\cf22 "Key: "} << model_key4torchvision << {\cf22 " could not be found!"} << std::endl;\par
341         \}\par
342         {\cf19 if} (debugOutput)\par
343             std::cerr << {\cf22 "Loading named buffers"} << std::endl;\par
344         {\cf19 for} ({\cf17 auto} &b : named_buffers())\par
345         \{\par
346             std::string model_key = b.key();\par
347             std::string model_key4torchvision = ourkey2torchvision(model_key);\par
348             {\cf19 if} (debugOutput)\par
349                 std::cerr << {\cf22 "Searching for: "} << model_key4torchvision << {\cf22 ": "} << b.value().sizes() << std::endl;\par
350             {\cf18 bool} foundit = {\cf17 false};\par
351             {\cf19 for} ({\cf17 auto} {\cf17 const} &w : weights)\par
352             \{\par
353                 {\cf19 if} (model_key4torchvision == w.key())\par
354                 \{\par
355                     {\cf19 if} (debugOutput)\par
356                         std::cerr << {\cf22 "Found it: "} << w.key() << std::endl;\par
357                     b.value().copy_(w.value().toTensor());\par
358                     foundit = {\cf17 true};\par
359                     {\cf19 break};\par
360                 \}\par
361             \}\par
362             {\cf19 if} (!foundit)\par
363                 std::cerr << {\cf22 "Key: "} << model_key4torchvision << {\cf22 " could not be found!"} << std::endl;\par
364         \}\par
365     \}\par
366 \par
377     {\cf17 static} torch::Tensor preprocess(cv::Mat img, {\cf18 bool} resizeOnly = {\cf17 false})\par
378     \{\par
379         {\cf17 constexpr} {\cf18 int} imageSizeBeforeCrop = 256;\par
380         {\cf17 constexpr} {\cf18 int} finalImageSize = 224;\par
381         {\cf17 constexpr} {\cf18 int} numChannels = 3; {\cf20 // colour}\par
382 \par
383         {\cf19 if} (img.depth() != CV_8U)\par
384             {\cf19 throw} std::invalid_argument({\cf22 "Image is not 8bit."});\par
385         {\cf19 if} (img.channels() != numChannels)\par
386             {\cf19 throw} std::invalid_argument({\cf22 "Image is not BGR / colour."});\par
387 \par
388         {\cf19 if} (resizeOnly)\par
389         \{\par
390             cv::resize(img, img, cv::Size(finalImageSize, finalImageSize));\par
391         \}\par
392         {\cf19 else}\par
393         \{\par
394             cv::resize(img, img, cv::Size(imageSizeBeforeCrop, imageSizeBeforeCrop));\par
395             {\cf17 constexpr} {\cf18 int} start = (imageSizeBeforeCrop - finalImageSize) / 2;\par
396             {\cf17 const} cv::Rect roi(start, start, finalImageSize, finalImageSize);\par
397             img = img(roi).clone();\par
398         \}\par
399         cv::cvtColor(img, img, cv::COLOR_BGR2RGB);\par
400 \par
401         torch::Tensor tensor = torch::from_blob(img.data, \{img.rows, img.cols, 3\}, torch::kByte);\par
402         tensor = tensor.permute(\{2, 0, 1\}).to(torch::kFloat).div_(255.0);\par
403         tensor = torch::data::transforms::Normalize(\{0.485, 0.456, 0.406\}, \{0.229, 0.224, 0.225\})(tensor);\par
404         {\cf19 return} tensor;\par
405     \}\par
406 \par
407     {\cf17 inline} {\cf18 int} make_divisible({\cf18 int} v, {\cf18 int} divisor = 8, {\cf18 int} min_value = -1){\cf17  const}\par
408 {\cf17     }\{\par
409         {\cf19 if} (min_value < 0)\par
410             min_value = divisor;\par
411         {\cf18 int} new_v = std::max(min_value, (({\cf18 int})((({\cf18 int})(v + divisor / 2)) / divisor)) * divisor);\par
412         {\cf19 if} (new_v < (0.9 * ({\cf18 float})v))\par
413             new_v += divisor;\par
414         {\cf19 return} new_v;\par
415     \}\par
416 \};\par
}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid Index\par 
\pard\plain 
{\tc \v Index}
{\field\fldedit {\*\fldinst INDEX \\c2 \\*MERGEFORMAT}{\fldrslt INDEX}}
}
