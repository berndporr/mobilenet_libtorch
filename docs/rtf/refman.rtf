{\rtf1\ansi\ansicpg1252\uc1 \deff0\deflang1033\deflangfe1033
{\fonttbl {\f0\froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}
{\f1\fswiss\fcharset0\fprq2{\*\panose 020b0604020202020204}Arial;}
{\f2\fmodern\fcharset0\fprq1{\*\panose 02070309020205020404}Courier New;}
{\f3\froman\fcharset2\fprq2{\*\panose 05050102010706020507}Symbol;}
}
{\colortbl;\red0\green0\blue0;\red0\green0\blue255;\red0\green255\blue255;\red0\green255\blue0;\red255\green0\blue255;\red255\green0\blue0;\red255\green255\blue0;\red255\green255\blue255;\red0\green0\blue128;\red0\green128\blue128;\red0\green128\blue0;\red128\green0\blue128;\red128\green0\blue0;\red128\green128\blue0;\red128\green128\blue128;\red192\green192\blue192;\red0\green128\blue0;\red96\green64\blue32;\rede0\green128\blue0;\red128\green0\blue0;\red128\green96\blue32;\red0\green32\blue128;\red0\green128\blue128;\red255\green0\blue255;\red0\green0\blue0;\red112\green0\blue112;\red255\green0\blue0;}
{\stylesheet
{\widctlpar\adjustright \fs20\cgrid \snext0 Normal;}
{\paperw11900\paperh16840\margl1800\margr1800\margt1440\margb1440\gutter0\ltrsect}
{\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid \sbasedon0 \snext0 heading 1;}
{\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid \sbasedon0 \snext0 heading 2;}
{\s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid \sbasedon0 \snext0 heading 3;}
{\s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext0 heading 4;}{\*\cs10 \additive Default Paragraph Font;}
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext0 heading 5;}{\*\cs10 \additive Default Paragraph Font;}
{\s15\qc\sb240\sa60\widctlpar\outlinelevel0\adjustright \b\f1\fs32\kerning28\cgrid \sbasedon0 \snext15 Title;}
{\s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid \sbasedon0 \snext16 Subtitle;}
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid \sbasedon0 \snext17 BodyText;}
{\s18\widctlpar\fs22\cgrid \sbasedon0 \snext18 DenseText;}
{\s28\widctlpar\tqc\tx4320\tqr\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext28 header;}
{\s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid \sbasedon0 \snext29 footer;}
{\s30\li360\sa60\sb120\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext30 GroupHeader;}
{\s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext41 Code Example 0;}
{\s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext42 Code Example 1;}
{\s42\li720\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext43 Code Example 2;}
{\s43\li1080\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext44 Code Example 3;}
{\s44\li1440\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext45 Code Example 4;}
{\s45\li1800\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext46 Code Example 5;}
{\s46\li2160\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext47 Code Example 6;}
{\s47\li2520\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext48 Code Example 7;}
{\s48\li2880\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext49 Code Example 8;}
{\s49\li3240\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext50 Code Example 9;}
{\s50\li3600\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext51 Code Example 10;}
{\s51\li3960\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext52 Code Example 11;}
{\s52\li4320\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext53 Code Example 12;}
{\s53\li4680\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext53 Code Example 13;}
{\s60\li0\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext61 List Continue 0;}
{\s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext62 List Continue 1;}
{\s62\li720\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext63 List Continue 2;}
{\s63\li1080\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext64 List Continue 3;}
{\s64\li1440\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext65 List Continue 4;}
{\s65\li1800\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext66 List Continue 5;}
{\s66\li2160\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext67 List Continue 6;}
{\s67\li2520\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext68 List Continue 7;}
{\s68\li2880\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext69 List Continue 8;}
{\s69\li3240\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext70 List Continue 9;}
{\s70\li3600\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext71 List Continue 10;}
{\s71\li3960\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext72 List Continue 11;}
{\s72\li4320\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext73 List Continue 12;}
{\s73\li4680\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext73 List Continue 13;}
{\s80\li0\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext81 DescContinue 0;}
{\s81\li360\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext82 DescContinue 1;}
{\s82\li720\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext83 DescContinue 2;}
{\s83\li1080\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext84 DescContinue 3;}
{\s84\li1440\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext85 DescContinue 4;}
{\s85\li1800\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext86 DescContinue 5;}
{\s86\li2160\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext87 DescContinue 6;}
{\s87\li2520\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext88 DescContinue 7;}
{\s88\li2880\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext89 DescContinue 8;}
{\s89\li3240\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext90 DescContinue 9;}
{\s90\li3600\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext91 DescContinue 10;}
{\s91\li3960\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext92 DescContinue 11;}
{\s92\li4320\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext93 DescContinue 12;}
{\s93\li4680\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext93 DescContinue 13;}
{\s100\li0\sa30\sb30\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext101 LatexTOC 0;}
{\s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext102 LatexTOC 1;}
{\s102\li720\sa24\sb24\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext103 LatexTOC 2;}
{\s103\li1080\sa21\sb21\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext104 LatexTOC 3;}
{\s104\li1440\sa18\sb18\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext105 LatexTOC 4;}
{\s105\li1800\sa15\sb15\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext106 LatexTOC 5;}
{\s106\li2160\sa12\sb12\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext107 LatexTOC 6;}
{\s107\li2520\sa9\sb9\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext108 LatexTOC 7;}
{\s108\li2880\sa6\sb6\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext109 LatexTOC 8;}
{\s109\li3240\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext110 LatexTOC 9;}
{\s110\li3600\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext111 LatexTOC 10;}
{\s111\li3960\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext112 LatexTOC 11;}
{\s112\li4320\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext113 LatexTOC 12;}
{\s113\li4680\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext113 LatexTOC 13;}
{\s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext121 \sautoupd List Bullet 0;}
{\s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext122 \sautoupd List Bullet 1;}
{\s122\fi-360\li1080\widctlpar\jclisttab\tx1080{\*\pn \pnlvlbody\ilvl0\ls3\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext123 \sautoupd List Bullet 2;}
{\s123\fi-360\li1440\widctlpar\jclisttab\tx1440{\*\pn \pnlvlbody\ilvl0\ls4\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext124 \sautoupd List Bullet 3;}
{\s124\fi-360\li1800\widctlpar\jclisttab\tx1800{\*\pn \pnlvlbody\ilvl0\ls5\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext125 \sautoupd List Bullet 4;}
{\s125\fi-360\li2160\widctlpar\jclisttab\tx2160{\*\pn \pnlvlbody\ilvl0\ls6\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext126 \sautoupd List Bullet 5;}
{\s126\fi-360\li2520\widctlpar\jclisttab\tx2520{\*\pn \pnlvlbody\ilvl0\ls7\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext127 \sautoupd List Bullet 6;}
{\s127\fi-360\li2880\widctlpar\jclisttab\tx2880{\*\pn \pnlvlbody\ilvl0\ls8\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext128 \sautoupd List Bullet 7;}
{\s128\fi-360\li3240\widctlpar\jclisttab\tx3240{\*\pn \pnlvlbody\ilvl0\ls9\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext129 \sautoupd List Bullet 8;}
{\s129\fi-360\li3600\widctlpar\jclisttab\tx3600{\*\pn \pnlvlbody\ilvl0\ls10\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext130 \sautoupd List Bullet 9;}
{\s130\fi-360\li3960\widctlpar\jclisttab\tx3960{\*\pn \pnlvlbody\ilvl0\ls11\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext131 \sautoupd List Bullet 10;}
{\s131\fi-360\li4320\widctlpar\jclisttab\tx4320{\*\pn \pnlvlbody\ilvl0\ls12\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext132 \sautoupd List Bullet 11;}
{\s132\fi-360\li4680\widctlpar\jclisttab\tx4680{\*\pn \pnlvlbody\ilvl0\ls13\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext133 \sautoupd List Bullet 12;}
{\s133\fi-360\li5040\widctlpar\jclisttab\tx5040{\*\pn \pnlvlbody\ilvl0\ls14\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext133 \sautoupd List Bullet 13;}
{\s140\fi-360\li360\widctlpar\fs20\cgrid \sbasedon0 \snext141 \sautoupd List Enum 0;}
{\s141\fi-360\li720\widctlpar\fs20\cgrid \sbasedon0 \snext142 \sautoupd List Enum 1;}
{\s142\fi-360\li1080\widctlpar\fs20\cgrid \sbasedon0 \snext143 \sautoupd List Enum 2;}
{\s143\fi-360\li1440\widctlpar\fs20\cgrid \sbasedon0 \snext144 \sautoupd List Enum 3;}
{\s144\fi-360\li1800\widctlpar\fs20\cgrid \sbasedon0 \snext145 \sautoupd List Enum 4;}
{\s145\fi-360\li2160\widctlpar\fs20\cgrid \sbasedon0 \snext146 \sautoupd List Enum 5;}
{\s146\fi-360\li2520\widctlpar\fs20\cgrid \sbasedon0 \snext147 \sautoupd List Enum 6;}
{\s147\fi-360\li2880\widctlpar\fs20\cgrid \sbasedon0 \snext148 \sautoupd List Enum 7;}
{\s148\fi-360\li3240\widctlpar\fs20\cgrid \sbasedon0 \snext149 \sautoupd List Enum 8;}
{\s149\fi-360\li3600\widctlpar\fs20\cgrid \sbasedon0 \snext150 \sautoupd List Enum 9;}
{\s150\fi-360\li3960\widctlpar\fs20\cgrid \sbasedon0 \snext151 \sautoupd List Enum 10;}
{\s151\fi-360\li4320\widctlpar\fs20\cgrid \sbasedon0 \snext152 \sautoupd List Enum 11;}
{\s152\fi-360\li4680\widctlpar\fs20\cgrid \sbasedon0 \snext153 \sautoupd List Enum 12;}
{\s153\fi-360\li5040\widctlpar\fs20\cgrid \sbasedon0 \snext153 \sautoupd List Enum 13;}
}
{\info 
{\title {\comment Mobilenet with Libtorch }Mobilenet with Libtorch}
{\comment Generated by doxygen 1.9.8.}
}\pard\plain 
\sectd\pgnlcrm
{\footer \s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid {\chpgn}}
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
\vertalc\qc\par\par\par\par\par\par\par
\pard\plain \s15\qc\sb240\sa60\widctlpar\outlinelevel0\adjustright \b\f1\fs32\kerning28\cgrid 
{\field\fldedit {\*\fldinst TITLE \\*MERGEFORMAT}{\fldrslt Mobilenet with Libtorch}}\par
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
\par
\par\par\par\par\par\par\par\par\par\par\par\par
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
{\field\fldedit {\*\fldinst AUTHOR \\*MERGEFORMAT}{\fldrslt AUTHOR}}\par
Version \par\page\page\vertalt
\pard\plain 
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid Table of Contents\par
\pard\plain \par
{\field\fldedit {\*\fldinst TOC \\f \\*MERGEFORMAT}{\fldrslt Table of contents}}\par
\pard\plain 
\sect \sbkpage \pgndec \pgnrestart
\sect \sectd \sbknone
{\footer \s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid {\chpgn}}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
\par \pard\plain 
\pard\plain \s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
MobileNetV2 libtorch\par \pard\plain 
{\tc\tcl1 \v MobileNetV2 libtorch}
{\xe \v MobileNetV2 libtorch}
{\bkmkstart AAAAAAAAAM}
{\bkmkend AAAAAAAAAM}
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\bkmkstart AAAAAAAAAN}
{\bkmkend AAAAAAAAAN}
C++ version of {\b MobileNetV2} using libtorch which can import the pre-trained weights from torchvision.\par
Importing the weights instead of using the JIT has the advantage that one can do transfer learning also on an edge device, for example, to adapt to different situations locally.\par
This implementation follows very closely the {\f2 torchvision implementation of mobilenet v2}.\par
Mobilenet is described {\f2 here}.\par
Then simply include {\f2 {\b mobilenet_v2.h}}  into your own project.\par
{\pard\plain \s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid {\tc\tcl1 Credit} \par}
(C) 2025 {\f2 Bernd Porr}, GPLv3 \par
}}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Hierarchical Index\par \pard\plain 
{\tc \v Hierarchical Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
Class Hierarchy\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid This inheritance list is sorted roughly, but not completely, alphabetically:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
torch::nn::Module
{
\par
\pard\plain \s102\li720\sa24\sb24\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
MobileNetV2\tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAB \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
}\par
}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Class Index\par \pard\plain 
{\tc \v Class Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
Class List\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid Here are the classes, structs, unions and interfaces with brief descriptions:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
{\b {\b MobileNetV2} ({\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Implementation of {\b MobileNetV2} as done in py-torchvision See: // {\f2 https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py#L66} })} \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAB \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
\par}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
File Index\par \pard\plain 
{\tc \v File Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
File List\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid Here is a list of all documented files with brief descriptions:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
{\b {\b mobilenet_v2.h} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAA \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
\par}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Class Documentation{\tc \v Class Documentation}
\par \pard\plain 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
MobileNetV2 Class Reference\par \pard\plain 
{\tc\tcl2 \v MobileNetV2}
{\xe \v MobileNetV2}
{\bkmkstart AAAAAAAAAB}
{\bkmkend AAAAAAAAAB}
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Implementation of {\b MobileNetV2} as done in py-torchvision See: // {\f2 https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py#L66}. }}\par
{
{\f2 #include <mobilenet_v2.h>}}\par
Inheritance diagram for MobileNetV2:{
\pard\plain 
\par\pard \qc {\field\flddirty {\*\fldinst INCLUDEPICTURE "classMobileNetV2__inherit__graph.png" \\d \\*MERGEFORMAT}{\fldrslt IMAGE}}\par
}
\par
Collaboration diagram for MobileNetV2:{
\pard\plain 
\par\pard \qc {\field\flddirty {\*\fldinst INCLUDEPICTURE "classMobileNetV2__coll__graph.png" \\d \\*MERGEFORMAT}{\fldrslt IMAGE}}\par
}
\par
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Public Member Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b MobileNetV2} (int num_classes=1000, float width_mult=1.0f, int round_nearest=8, float dropout=0.2)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Construct a new {\b MobileNetV2} object. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b getNinputChannels4Classifier} () const\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Gets the number of input channels for the classfier. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
torch::Tensor {\b forward} (torch::Tensor x)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Performs the forward pass. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

void {\b initialize_weights} (){\bkmkstart AAAAAAAAAC}
{\bkmkend AAAAAAAAAC}
\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Initialize conv/bn/linear similar to torchvision defaults. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
void {\b load_weights} (std::string pt)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Loads a .pt weight file containing a dict with key/parameter pairs. }{
}\par
}\par}
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Static Public Member Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
static torch::Tensor {\b preprocess} (cv::Mat img, bool resizeOnly=false)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Preprocessing of an openCV image for inference or learning. }{
}\par
}\par}
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Public Attributes\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
torch::nn::Sequential {\b classifier}\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Classifier submodule. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
torch::nn::Sequential {\b features}\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Features submodule. }{
}\par
}\par}
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Static Public Attributes\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
static constexpr char {\b featuresModuleName} [] = "features"\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Name of the features submodule. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
static constexpr char {\b classifierModuleName} [] = "classifier"\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Name of the classifier submodule. }{
}\par
}\par}
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Implementation of {\b MobileNetV2} as done in py-torchvision See: // {\f2 https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py#L66}. \par
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Constructor & Destructor Documentation\par
\pard\plain 
{\xe \v MobileNetV2\:MobileNetV2}
{\xe \v MobileNetV2\:MobileNetV2}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
MobileNetV2::MobileNetV2 (int  {\i num_classes} = {\f2 1000}, float  {\i width_mult} = {\f2 1.0f}, int  {\i round_nearest} = {\f2 8}, float  {\i dropout} = {\f2 0.2}){\f2 [inline]}}}
\par
{\bkmkstart AAAAAAAAAD}
{\bkmkend AAAAAAAAAD}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Construct a new {\b MobileNetV2} object. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
If you want to load the weights from torchvision into the classifier use the default values for the parameters.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i num_classes} \cell }{Number of classes. \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i width_mult} \cell }{Width multiplier - adjusts number of channels in each layer by this amount. \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i round_nearest} \cell }{Round the number of channels in each layer to be a multiple of this number. \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i dropout} \cell }{Dropout probability for the dropout layer in the classifier. \cell }
{\row }
}
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Member Function Documentation\par
\pard\plain 
{\xe \v forward\:MobileNetV2}
{\xe \v MobileNetV2\:forward}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
torch::Tensor MobileNetV2::forward (torch::Tensor  {\i x}){\f2 [inline]}}}
\par
{\bkmkstart AAAAAAAAAE}
{\bkmkend AAAAAAAAAE}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Performs the forward pass. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\par
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i x} \cell }{The batch of input images. \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
torch::Tensor The category scores for the different labels. \par
}}}}
{\xe \v getNinputChannels4Classifier\:MobileNetV2}
{\xe \v MobileNetV2\:getNinputChannels4Classifier}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
int MobileNetV2::getNinputChannels4Classifier () const{\f2 [inline]}}}
\par
{\bkmkstart AAAAAAAAAF}
{\bkmkend AAAAAAAAAF}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Gets the number of input channels for the classfier. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
This will make it easy to replace the classifier with anything the user wants by creating their own torch::nn::Sequential() for the classifier.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
int The number of intput channels to the classifer class "classfier". \par
}}}}
{\xe \v load_weights\:MobileNetV2}
{\xe \v MobileNetV2\:load_weights}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
void MobileNetV2::load_weights (std::string  {\i pt}){\f2 [inline]}}}
\par
{\bkmkstart AAAAAAAAAG}
{\bkmkend AAAAAAAAAG}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Loads a .pt weight file containing a dict with key/parameter pairs. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
See {\f2 https://github.com/pytorch/pytorch/issues/36577}\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i pt} \cell }{filename of the .pt weight file. \cell }
{\row }
}
}}
{\xe \v preprocess\:MobileNetV2}
{\xe \v MobileNetV2\:preprocess}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
static torch::Tensor MobileNetV2::preprocess (cv::Mat  {\i img}, bool  {\i resizeOnly} = {\f2 false}){\f2 [inline]}, {\f2 [static]}}}
\par
{\bkmkstart AAAAAAAAAH}
{\bkmkend AAAAAAAAAH}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Preprocessing of an openCV image for inference or learning. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
The images are resized to 256x256, followed by a central crop of 224x224. Finally the values are first rescaled to [0.0, 1.0] and then normalized using mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225].\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i img} \cell }{8bit BGR openCV image with an aspect ratio of 1:1. \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i resizeOnly} \cell }{If true the image is only resized to 224x224 but not cropped. Default: false. \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
torch::Tensor The image as a tensor ready to be used for inference and learning. \par
}}}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Member Data Documentation\par
\pard\plain 
{\xe \v classifier\:MobileNetV2}
{\xe \v MobileNetV2\:classifier}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
torch::nn::Sequential MobileNetV2::classifier}}
\par
{\bkmkstart AAAAAAAAAI}
{\bkmkend AAAAAAAAAI}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Classifier submodule. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
This can be replaced by a custom classifier for transfer learning. \par
}}
{\xe \v classifierModuleName\:MobileNetV2}
{\xe \v MobileNetV2\:classifierModuleName}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
constexpr char MobileNetV2::classifierModuleName[] = "classifier"{\f2 [static]}, {\f2 [constexpr]}}}
\par
{\bkmkstart AAAAAAAAAJ}
{\bkmkend AAAAAAAAAJ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Name of the classifier submodule. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
This is used for module registration and appears as part of the key in named_parametes. The name of the classifier module is needed when replacing the default classifier. \par
}}
{\xe \v features\:MobileNetV2}
{\xe \v MobileNetV2\:features}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
torch::nn::Sequential MobileNetV2::features}}
\par
{\bkmkstart AAAAAAAAAK}
{\bkmkend AAAAAAAAAK}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Features submodule. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
This needs to be accessible for transfer learning which then will disable learning here. \par
}}
{\xe \v featuresModuleName\:MobileNetV2}
{\xe \v MobileNetV2\:featuresModuleName}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
constexpr char MobileNetV2::featuresModuleName[] = "features"{\f2 [static]}, {\f2 [constexpr]}}}
\par
{\bkmkstart AAAAAAAAAL}
{\bkmkend AAAAAAAAAL}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Name of the features submodule. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
This is used for module registration and appears as part of the key in named_parametes. \par
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
The documentation for this class was generated from the following file:{\par
\pard\plain \s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
mobilenet_v2.h\par
}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
File Documentation{\tc \v File Documentation}
\par \pard\plain 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
mobilenet_v2.h\par \pard\plain 
{\bkmkstart AAAAAAAAAA}
{\bkmkend AAAAAAAAAA}
{
\pard\plain \s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 1 {\cf21 #pragma once}\par
2 \par
3 {\cf21 #include <torch/torch.h>}\par
4 {\cf21 #include <vector>}\par
5 {\cf21 #include <algorithm>}\par
6 {\cf21 #include <fstream>}\par
7 {\cf21 #include <string>}\par
8 {\cf21 #include <regex>}\par
9 {\cf21 #include <filesystem>}\par
10 {\cf21 #include <iostream>}\par
11 {\cf21 #include <system_error>}\par
12 {\cf21 #include <opencv2/opencv.hpp>}\par
13 \par
14 {\cf20 /***}\par
15 {\cf20  * MobileNetV2 C++ Implementation (LibTorch).}\par
16 {\cf20  * It's able to load pre-trained weights from torchvision.}\par
17 {\cf20  * (c) 2025 Bernd Porr, GPLv3.}\par
18 {\cf20  ***/}\par
19 \par
20 {\cf21 #ifdef NDEBUG}\par
21 {\cf17 constexpr} {\cf18 bool} debugOutput = {\cf17 false};\par
22 {\cf21 #else}\par
23 {\cf17 constexpr} {\cf18 bool} debugOutput = {\cf17 true};\par
24 {\cf21 #endif}\par
25 \par
30 {\cf17 class }MobileNetV2 : {\cf17 public} torch::nn::Module\par
31 \{\par
32 {\cf17 public}:\par
43     MobileNetV2({\cf18 int} num_classes = 1000, {\cf18 float} width_mult = 1.0f, {\cf18 int} round_nearest = 8, {\cf18 float} dropout = 0.2)\par
44     \{\par
45         {\cf18 int} input_channels = 32;\par
46         input_channels = make_divisible(input_channels * width_mult, round_nearest);\par
47         features_output_channels = make_divisible(features_output_channels * std::max(1.0f, width_mult), round_nearest);\par
48 \par
49         features = torch::nn::Sequential();\par
50 \par
51         features->push_back(\par
52             Conv2dNormActivation(3,\par
53                                  input_channels,\par
54                                  {\cf20 /*kernel_size=*/}3,\par
55                                  {\cf20 /*stride =*/}2));\par
56 \par
57         {\cf20 // inverted residual blocks}\par
58         {\cf19 for} ({\cf17 const} {\cf17 auto} &cfg : inverted_residual_setting)\par
59         \{\par
60             {\cf17 const} {\cf18 int} t = cfg[0];\par
61             {\cf17 const} {\cf18 int} c = cfg[1];\par
62             {\cf17 const} {\cf18 int} n = cfg[2];\par
63             {\cf17 const} {\cf18 int} s = cfg[3];\par
64 \par
65             {\cf18 int} output_channel = make_divisible(c * width_mult, round_nearest);\par
66             {\cf19 for} ({\cf18 int} i = 0; i < n; ++i)\par
67             \{\par
68                 {\cf17 const} {\cf18 int} stride = (i == 0) ? s : 1;\par
69                 features->push_back(\par
70                     InvertedResidual(input_channels, output_channel, stride, t));\par
71                 input_channels = output_channel;\par
72             \}\par
73         \}\par
74 \par
75         features->push_back(\par
76             Conv2dNormActivation(input_channels,\par
77                                  features_output_channels,\par
78                                  {\cf20 /*kernel_size=*/}1));\par
79 \par
80         register_module(featuresModuleName, features);\par
81 \par
82         {\cf20 // classifier: Dropout + Linear}\par
83         classifier = torch::nn::Sequential();\par
84         classifier->push_back(torch::nn::Dropout(torch::nn::DropoutOptions(dropout)));\par
85         classifier->push_back(torch::nn::Linear(torch::nn::LinearOptions(features_output_channels, num_classes)));\par
86         register_module(classifierModuleName, classifier);\par
87     \}\par
88 \par
93     {\cf17 static} {\cf17 constexpr} {\cf18 char} featuresModuleName[] = {\cf22 "features"};\par
94 \par
101     {\cf17 static} {\cf17 constexpr} {\cf18 char} classifierModuleName[] = {\cf22 "classifier"};\par
102 \par
110     {\cf18 int} getNinputChannels4Classifier(){\cf17  const}\par
111 {\cf17     }\{\par
112         {\cf19 return} features_output_channels;\par
113     \}\par
114 \par
121     torch::Tensor forward(torch::Tensor x)\par
122     \{\par
123         x = features->forward(x);\par
124         {\cf17 const} torch::nn::functional::AdaptiveAvgPool2dFuncOptions &ar = torch::nn::functional::AdaptiveAvgPool2dFuncOptions(\{1, 1\});\par
125         x = torch::nn::functional::adaptive_avg_pool2d(x, ar);\par
126         x = torch::flatten(x, 1);\par
127         x = classifier->forward(x);\par
128         {\cf19 return} x;\par
129     \}\par
130 \par
134     {\cf18 void} initialize_weights()\par
135     \{\par
136         {\cf19 for} ({\cf17 auto} &module : modules({\cf20 /*include_self=*/}{\cf17 false}))\par
137         \{\par
138             {\cf19 if} ({\cf17 auto} M = {\cf17 dynamic_cast<}torch::nn::Conv2dImpl *{\cf17 >}(module.get()))\par
139             \{\par
140                 torch::nn::init::kaiming_normal_(M->weight, {\cf20 /*a=*/}0, torch::kFanOut, torch::kReLU);\par
141                 {\cf19 if} (M->options.bias())\par
142                     torch::nn::init::zeros_(M->bias);\par
143             \}\par
144             {\cf19 else} {\cf19 if} ({\cf17 auto} M = {\cf17 dynamic_cast<}torch::nn::BatchNorm2dImpl *{\cf17 >}(module.get()))\par
145             \{\par
146                 torch::nn::init::ones_(M->weight);\par
147                 torch::nn::init::zeros_(M->bias);\par
148             \}\par
149             {\cf19 else} {\cf19 if} ({\cf17 auto} M = {\cf17 dynamic_cast<}torch::nn::LinearImpl *{\cf17 >}(module.get()))\par
150             \{\par
151                 torch::nn::init::normal_(M->weight, 0.0, 0.01);\par
152                 torch::nn::init::zeros_(M->bias);\par
153             \}\par
154         \}\par
155     \}\par
156 \par
163     {\cf18 void} load_weights(std::string pt)\par
164     \{\par
165         std::ifstream input(pt, std::ios::binary);\par
166         input.exceptions(input.failbit);\par
167         std::vector<char> bytes(\par
168             (std::istreambuf_iterator<char>(input)),\par
169             (std::istreambuf_iterator<char>()));\par
170         input.close();\par
171         {\cf17 const} c10::Dict<c10::IValue, c10::IValue> weights = torch::pickle_load(bytes).toGenericDict();\par
172         {\cf19 if} (debugOutput)\par
173         \{\par
174             std::cerr << {\cf22 "Parameters we have in this model here: "} << std::endl;\par
175             {\cf19 for} ({\cf17 auto} {\cf17 const} &m : named_parameters())\par
176             \{\par
177                 {\cf17 auto} k = ourkey2torchvision(m.key());\par
178                 std::cerr << m.key() << {\cf22 "->"} << k << {\cf22 ": "} << m.value().sizes() << std::endl;\par
179             \}\par
180             std::cerr << {\cf22 "Named buffers we have in this model here: "} << std::endl;\par
181             {\cf19 for} ({\cf17 const} {\cf17 auto} &b : named_buffers())\par
182             \{\par
183                 {\cf17 auto} k = ourkey2torchvision(b.key());\par
184                 std::cout << b.key() << {\cf22 "->"} << k << {\cf22 ": "} << b.value().sizes() << std::endl;\par
185             \}\par
186             std::cerr << {\cf22 "Parameters we have in the weight file "} << pt << {\cf22 ":"} << std::endl;\par
187             {\cf19 for} ({\cf17 auto} {\cf17 const} &w : weights)\par
188             \{\par
189                 std::cerr << w.key() << {\cf22 ": "} << w.value().toTensor().sizes() << std::endl;\par
190             \}\par
191         \}\par
192         torch::NoGradGuard no_grad;\par
193         {\cf19 if} (debugOutput)\par
194             std::cerr << {\cf22 "Loading weights"} << std::endl;\par
195         {\cf19 for} ({\cf17 auto} &m : named_parameters())\par
196         \{\par
197             {\cf17 const} std::string model_key = m.key();\par
198             {\cf17 const} std::string model_key4torchvision = ourkey2torchvision(model_key);\par
199             {\cf19 if} (debugOutput)\par
200                 std::cerr << {\cf22 "Searching for: "} << model_key4torchvision << {\cf22 ": "} << m.value().sizes() << std::endl;\par
201             {\cf18 bool} foundit = {\cf17 false};\par
202             {\cf19 for} ({\cf17 auto} {\cf17 const} &w : weights)\par
203             \{\par
204                 {\cf19 if} (model_key4torchvision == w.key())\par
205                 \{\par
206                     {\cf19 if} (debugOutput)\par
207                         std::cerr << {\cf22 "Found it: "} << w.key() << std::endl;\par
208                     m.value().copy_(w.value().toTensor());\par
209                     foundit = {\cf17 true};\par
210                     {\cf19 break};\par
211                 \}\par
212             \}\par
213             {\cf19 if} (!foundit)\par
214                 std::cerr << {\cf22 "Key: "} << model_key4torchvision << {\cf22 " could not be found!"} << std::endl;\par
215         \}\par
216         {\cf19 if} (debugOutput)\par
217             std::cerr << {\cf22 "Loading named buffers"} << std::endl;\par
218         {\cf19 for} ({\cf17 auto} &b : named_buffers())\par
219         \{\par
220             std::string model_key = b.key();\par
221             std::string model_key4torchvision = ourkey2torchvision(model_key);\par
222             {\cf19 if} (debugOutput)\par
223                 std::cerr << {\cf22 "Searching for: "} << model_key4torchvision << {\cf22 ": "} << b.value().sizes() << std::endl;\par
224             {\cf18 bool} foundit = {\cf17 false};\par
225             {\cf19 for} ({\cf17 auto} {\cf17 const} &w : weights)\par
226             \{\par
227                 {\cf19 if} (model_key4torchvision == w.key())\par
228                 \{\par
229                     {\cf19 if} (debugOutput)\par
230                         std::cerr << {\cf22 "Found it: "} << w.key() << std::endl;\par
231                     b.value().copy_(w.value().toTensor());\par
232                     foundit = {\cf17 true};\par
233                     {\cf19 break};\par
234                 \}\par
235             \}\par
236             {\cf19 if} (!foundit)\par
237                 std::cerr << {\cf22 "Key: "} << model_key4torchvision << {\cf22 " could not be found!"} << std::endl;\par
238         \}\par
239     \}\par
240 \par
251     {\cf17 static} torch::Tensor preprocess(cv::Mat img, {\cf18 bool} resizeOnly = {\cf17 false})\par
252     \{\par
253         {\cf17 constexpr} {\cf18 int} imageSizeBeforeCrop = 256;\par
254         {\cf17 constexpr} {\cf18 int} finalImageSize = 224;\par
255         {\cf17 constexpr} {\cf18 int} numChannels = 3; {\cf20 // colour}\par
256 \par
257         {\cf19 if} (img.depth() != CV_8U)\par
258             {\cf19 throw} std::invalid_argument({\cf22 "Image is not 8bit."});\par
259         {\cf19 if} (img.channels() != numChannels)\par
260             {\cf19 throw} std::invalid_argument({\cf22 "Image is not BGR / colour."});\par
261 \par
262         {\cf19 if} (resizeOnly)\par
263         \{\par
264             cv::resize(img, img, cv::Size(finalImageSize, finalImageSize));\par
265         \}\par
266         {\cf19 else}\par
267         \{\par
268             cv::resize(img, img, cv::Size(imageSizeBeforeCrop, imageSizeBeforeCrop));\par
269             {\cf17 constexpr} {\cf18 int} start = (imageSizeBeforeCrop - finalImageSize) / 2;\par
270             {\cf17 const} cv::Rect roi(start, start, finalImageSize, finalImageSize);\par
271             img = img(roi).clone();\par
272         \}\par
273         cv::cvtColor(img, img, cv::COLOR_BGR2RGB);\par
274 \par
275         torch::Tensor tensor = torch::from_blob(img.data, \{img.rows, img.cols, 3\}, torch::kByte);\par
276         tensor = tensor.permute(\{2, 0, 1\}).to(torch::kFloat).div_(255.0);\par
277         tensor = torch::data::transforms::Normalize(\{0.485, 0.456, 0.406\}, \{0.229, 0.224, 0.225\})(tensor);\par
278         {\cf19 return} tensor;\par
279     \}\par
280 \par
285     torch::nn::Sequential classifier;\par
286 \par
291     torch::nn::Sequential features;\par
292 \par
293 {\cf17 private}:\par
294     {\cf20 // Helper which maps the libtorch keys to pytorch keys.}\par
295     std::string ourkey2torchvision(std::string k){\cf17  const}\par
296 {\cf17     }\{\par
297         {\cf20 // called simply "conv" in the weights file}\par
298         k = std::regex_replace(k, std::regex(InvertedResidual::className), {\cf22 "conv"});\par
299         {\cf20 // not used at all in the weights file}\par
300         {\cf17 const} std::string r = std::string(Conv2dNormActivation::className) + {\cf22 "\\\\."};\par
301         k = std::regex_replace(k, std::regex(r), {\cf22 ""});\par
302         {\cf19 return} k;\par
303     \}\par
304 \par
305     {\cf20 // Makes a value divisible.}\par
306     {\cf17 inline} {\cf18 int} make_divisible({\cf18 int} v, {\cf18 int} divisor = 8, {\cf18 int} min_value = -1){\cf17  const}\par
307 {\cf17     }\{\par
308         {\cf19 if} (min_value < 0)\par
309             min_value = divisor;\par
310         {\cf18 int} new_v = std::max(min_value, (({\cf18 int})((({\cf18 int})(v + divisor / 2)) / divisor)) * divisor);\par
311         {\cf19 if} (new_v < (0.9 * ({\cf18 float})v))\par
312             new_v += divisor;\par
313         {\cf19 return} new_v;\par
314     \}\par
315 \par
316     {\cf20 // Features output channels but can be scaled.}\par
317     {\cf18 int} features_output_channels = 1280;\par
318 \par
319     {\cf20 // MobileNetV2 inverted residual settings:}\par
320     {\cf20 // t, c, n, s  (expansion, output channels, repeats, stride)}\par
321     {\cf17 const} std::vector<std::array<int, 4>> inverted_residual_setting = \{\par
322         \{1, 16, 1, 1\},\par
323         \{6, 24, 2, 2\},\par
324         \{6, 32, 3, 2\},\par
325         \{6, 64, 4, 2\},\par
326         \{6, 96, 3, 1\},\par
327         \{6, 160, 3, 2\},\par
328         \{6, 320, 1, 1\},\par
329     \};\par
330 \par
335     {\cf17 class }Conv2dNormActivation : {\cf17 public} torch::nn::Module\par
336     \{\par
337     {\cf17 public}:\par
338         {\cf17 static} {\cf17 constexpr} {\cf18 char} className[] = {\cf22 "Conv2dNormActivation"};\par
339 \par
340         {\cf17 static} {\cf17 inline} torch::Tensor relu6({\cf17 const} torch::Tensor &x)\par
341         \{\par
342             {\cf19 return} torch::clamp(torch::relu(x), 0, 6);\par
343         \}\par
344 \par
345         Conv2dNormActivation({\cf18 int} in_channels,\par
346                              {\cf18 int} out_channels,\par
347                              {\cf18 int} kernel_size = 3,\par
348                              {\cf18 int} stride = 1,\par
349                              {\cf18 int} padding = -1,\par
350                              {\cf18 int} groups = 1)\par
351         \{\par
352             {\cf17 const} {\cf18 int} dilation = 1;\par
353             conv = torch::nn::Sequential();\par
354             {\cf19 if} (padding < 0)\par
355             \{\par
356                 padding = (kernel_size - 1) / 2 * dilation;\par
357             \}\par
358             conv->push_back(torch::nn::Conv2d(\par
359                 torch::nn::Conv2dOptions(in_channels, out_channels, kernel_size)\par
360                     .stride(stride)\par
361                     .padding(padding)\par
362                     .groups(groups)\par
363                     .bias({\cf17 false})));\par
364             conv->push_back(torch::nn::BatchNorm2d(torch::nn::BatchNorm2dOptions(out_channels)));\par
365             conv->push_back(torch::nn::Functional(relu6));\par
366             register_module(className, conv);\par
367         \}\par
368 \par
369         torch::Tensor forward({\cf17 const} torch::Tensor &x)\par
370         \{\par
371             {\cf19 return} conv->forward(x);\par
372         \}\par
373 \par
374     {\cf17 private}:\par
375         torch::nn::Sequential conv\{{\cf17 nullptr}\};\par
376     \};\par
377 \par
382     {\cf17 class }InvertedResidual : {\cf17 public} torch::nn::Module\par
383     \{\par
384     {\cf17 public}:\par
385         {\cf17 static} {\cf17 constexpr} {\cf18 char} className[] = {\cf22 "InvertedResidual"};\par
386 \par
387         InvertedResidual({\cf18 int} inp, {\cf18 int} oup, {\cf18 int} stride, {\cf18 int} expand_ratio)\par
388         \{\par
389             {\cf19 if} ((stride < 1) || (stride > 2))\par
390             \{\par
391                 {\cf19 throw} std::invalid_argument({\cf22 "Stride needs to be 1 or 2."});\par
392             \}\par
393             {\cf17 const} {\cf18 int} hidden_dim = (int)round(inp * expand_ratio);\par
394             use_res_connect = (stride == 1) && (inp == oup);\par
395 \par
396             conv = torch::nn::Sequential();\par
397 \par
398             {\cf19 if} (expand_ratio != 1)\par
399             \{\par
400                 conv->push_back(\par
401                     Conv2dNormActivation(inp,\par
402                                          hidden_dim,\par
403                                          {\cf20 /*kernel_size*/} 1));\par
404             \}\par
405 \par
406             conv->push_back(\par
407                 Conv2dNormActivation(hidden_dim,\par
408                                      hidden_dim,\par
409                                      {\cf20 /*kernel_size=*/}3,\par
410                                      {\cf20 /*stride=*/}stride,\par
411                                      {\cf20 /*padding=*/}-1,\par
412                                      {\cf20 /*groups=*/}hidden_dim));\par
413 \par
414             conv->push_back(torch::nn::Conv2d(\par
415                 torch::nn::Conv2dOptions(hidden_dim, oup,\par
416                                          {\cf20 /*kernel_size=*/}1)\par
417                     .stride(1)\par
418                     .padding(0)\par
419                     .bias({\cf17 false})));\par
420             conv->push_back(torch::nn::BatchNorm2d(torch::nn::BatchNorm2dOptions(oup)));\par
421 \par
422             register_module(className, conv);\par
423         \}\par
424 \par
425         torch::Tensor forward({\cf17 const} torch::Tensor &x)\par
426         \{\par
427             {\cf19 if} (use_res_connect)\par
428             \{\par
429                 {\cf19 return} x + conv->forward(x);\par
430             \}\par
431             {\cf19 else}\par
432             \{\par
433                 {\cf19 return} conv->forward(x);\par
434             \}\par
435         \}\par
436         torch::nn::Sequential conv\{{\cf17 nullptr}\};\par
437         {\cf18 bool} use_res_connect;\par
438     \};\par
439 \};\par
}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid Index\par 
\pard\plain 
{\tc \v Index}
{\field\fldedit {\*\fldinst INDEX \\c2 \\*MERGEFORMAT}{\fldrslt INDEX}}
}
